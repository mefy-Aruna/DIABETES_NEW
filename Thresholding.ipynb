{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thresholding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLRXIZ3D33s6YlgOrpWl5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mefy-Aruna/DIABETES_NEW/blob/main/Thresholding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtF0fMGua_UF"
      },
      "source": [
        "# Importing filtered data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNun1_4-R_pc"
      },
      "source": [
        "import pandas as pd\n",
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from fancyimpute import IterativeImputer\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKZUrP6zTTBr",
        "outputId": "e17421ff-ba2e-4b50-a617-87bc30040b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "df = pd.read_excel(r'filtered.xlsx')\n",
        "df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-444633952195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'filtered.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'filtered.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5y69wt4UnWM"
      },
      "source": [
        "df.to_csv('filtered.csv',index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg_l-YBgU8CD",
        "outputId": "cd822c64-c282-48d9-e86c-b8478ba34324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "data = pd.read_csv(r'filtered.csv')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>dia_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>glucose</th>\n",
              "      <th>trigs</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>Diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>11.77</td>\n",
              "      <td>118.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.7</td>\n",
              "      <td>110.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>2.37</td>\n",
              "      <td>172.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.3</td>\n",
              "      <td>114.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>168.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.1</td>\n",
              "      <td>108.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>3.74</td>\n",
              "      <td>144.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.6</td>\n",
              "      <td>134.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>104.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.9</td>\n",
              "      <td>130.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>11.43</td>\n",
              "      <td>171.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>39.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>136.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>33.20</td>\n",
              "      <td>197.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>6.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.5</td>\n",
              "      <td>128.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>3.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.7</td>\n",
              "      <td>150.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>4.16</td>\n",
              "      <td>223.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>5.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  age   bmi  waist_cm  ...  trigs  a1c  glucose.1  Diabetes \n",
              "0          1   21  18.2      82.0  ...   54.0  5.0       88.0        0.0\n",
              "1          0   21  25.9      93.7  ...   83.0  5.2       88.0        0.0\n",
              "2          0   21  29.5     102.3  ...  256.0  5.1        NaN        0.0\n",
              "3          0   21  17.9      69.1  ...   57.0  5.1       95.0        0.0\n",
              "4          0   21  30.6     101.6  ...   70.0  6.0       95.0        0.0\n",
              "...      ...  ...   ...       ...  ...    ...  ...        ...        ...\n",
              "5201       0   77  32.8     115.9  ...  130.0  6.5      134.0        1.0\n",
              "5202       0   77  32.9     122.2  ...    NaN  6.2       98.0        0.0\n",
              "5203       0   77  39.2       NaN  ...  169.0  6.3        NaN        1.0\n",
              "5204       1   77  36.5     119.5  ...   67.0  6.2      103.0        0.0\n",
              "5205       1   77  34.8     104.7  ...  117.0  5.7        NaN        1.0\n",
              "\n",
              "[5206 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQTW2s0AeWY_"
      },
      "source": [
        "y = data.iloc[:, 12].values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5kVrMStbJS2"
      },
      "source": [
        "# Imputation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75-6Xvj6bO8U"
      },
      "source": [
        "from fancyimpute import IterativeImputer as MICE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xKXRPUWbwyS"
      },
      "source": [
        "from fancyimpute import IterativeImputer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuTDuWTHbyDj",
        "outputId": "c0fd232e-be00-476a-f8b3-c6c301a17104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "pip install mice"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mice\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/d4/1eb8e7d9fb3c2341fd9efd1514bc81439dd20ea987548f438c4a79d92c99/mice-0.0.1a0.tar.gz\n",
            "Building wheels for collected packages: mice\n",
            "  Building wheel for mice (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mice: filename=mice-0.0.1a0-cp36-none-any.whl size=1045 sha256=3c76b28ad2685e1b89763c6bf4abb929d58c089eaff3474feade319998b3a5e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e7/4f/1b0c52cfdb6dc95dd0ba1459459f8e4ed33cab25eccdd78d65\n",
            "Successfully built mice\n",
            "Installing collected packages: mice\n",
            "Successfully installed mice-0.0.1a0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdGRXzlxb6uw",
        "outputId": "98845baf-8b3b-414b-f60d-298d1b3205d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        }
      },
      "source": [
        "pip install fancyimpute"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fancyimpute in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (2.3.0)\n",
            "Requirement already satisfied: knnimpute in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (0.1.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (1.18.5)\n",
            "Requirement already satisfied: cvxpy>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (1.0.31)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (0.22.2.post1)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (2.4.3)\n",
            "Requirement already satisfied: np-utils in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (0.5.12.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (2.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (1.1.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (3.12.4)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (0.35.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (2.10.0)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0.6->fancyimpute) (0.6.1)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0.6->fancyimpute) (2.1.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0.6->fancyimpute) (0.70.10)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0.6->fancyimpute) (2.0.7.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->fancyimpute) (0.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->fancyimpute) (3.13)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.6/dist-packages (from np-utils->fancyimpute) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow->fancyimpute) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (2.23.0)\n",
            "Requirement already satisfied: dill>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from multiprocess->cvxpy>=1.0.6->fancyimpute) (0.3.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (2.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (3.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjeAAG4lcB7Z"
      },
      "source": [
        "from fancyimpute import IterativeImputer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uMio2fOcDlT"
      },
      "source": [
        "mice_impute = IterativeImputer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUNOqQZgcRws",
        "outputId": "6d22d880-7e76-4954-ee70-48c692804a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "mice_data = mice_impute.fit_transform(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRAj0dxucZ6_",
        "outputId": "75aea03c-73aa-4ec3-efc2-e2f88829c2f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "mice_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1.        ,  21.        ,  18.2       , ...,   5.        ,\n",
              "         88.        ,   0.        ],\n",
              "       [  0.        ,  21.        ,  25.9       , ...,   5.2       ,\n",
              "         88.        ,   0.        ],\n",
              "       [  0.        ,  21.        ,  29.5       , ...,   5.1       ,\n",
              "         94.16074483,   0.        ],\n",
              "       ...,\n",
              "       [  0.        ,  77.        ,  39.2       , ...,   6.3       ,\n",
              "        106.72079006,   1.        ],\n",
              "       [  1.        ,  77.        ,  36.5       , ...,   6.2       ,\n",
              "        103.        ,   0.        ],\n",
              "       [  1.        ,  77.        ,  34.8       , ...,   5.7       ,\n",
              "         96.8663047 ,   1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TuNx14Qcco8",
        "outputId": "cad66f10-7d0b-41c3-92ca-45c8af4d834e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "data_n = pd.DataFrame(mice_data)\n",
        "data_n.to_csv(\"miceDataset.csv\", index=False, header=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4b9cba19a92c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmice_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"miceDataset.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mice_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vaw6SswFci3o"
      },
      "source": [
        "data = pd.read_csv(r'miceDataset.csv')"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF37RAmlXEd8"
      },
      "source": [
        "data1 = pd.read_csv(r'miceDataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsxvtK0Dcld9",
        "outputId": "f03b0996-c21a-40cc-fb0d-4823832c6dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>dia_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>glucose</th>\n",
              "      <th>trigs</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>Diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>50.00000</td>\n",
              "      <td>11.77</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.700000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>60.00000</td>\n",
              "      <td>2.37</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.300000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>72.00000</td>\n",
              "      <td>3.73</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>94.160745</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.100000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>3.74</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.600000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>64.00000</td>\n",
              "      <td>3.13</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.900000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>64.00000</td>\n",
              "      <td>11.43</td>\n",
              "      <td>171.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.200000</td>\n",
              "      <td>140.666578</td>\n",
              "      <td>76.05274</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>207.939424</td>\n",
              "      <td>91.927995</td>\n",
              "      <td>205.687652</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>39.2</td>\n",
              "      <td>128.090281</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>33.20</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>6.3</td>\n",
              "      <td>106.720790</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.500000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>74.00000</td>\n",
              "      <td>3.92</td>\n",
              "      <td>181.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.700000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>78.00000</td>\n",
              "      <td>4.16</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>5.7</td>\n",
              "      <td>96.866305</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  age   bmi    waist_cm  ...       trigs  a1c   glucose.1  Diabetes \n",
              "0          1   21  18.2   82.000000  ...   54.000000  5.0   88.000000        0.0\n",
              "1          0   21  25.9   93.700000  ...   83.000000  5.2   88.000000        0.0\n",
              "2          0   21  29.5  102.300000  ...  256.000000  5.1   94.160745        0.0\n",
              "3          0   21  17.9   69.100000  ...   57.000000  5.1   95.000000        0.0\n",
              "4          0   21  30.6  101.600000  ...   70.000000  6.0   95.000000        0.0\n",
              "...      ...  ...   ...         ...  ...         ...  ...         ...        ...\n",
              "5201       0   77  32.8  115.900000  ...  130.000000  6.5  134.000000        1.0\n",
              "5202       0   77  32.9  122.200000  ...  205.687652  6.2   98.000000        0.0\n",
              "5203       0   77  39.2  128.090281  ...  169.000000  6.3  106.720790        1.0\n",
              "5204       1   77  36.5  119.500000  ...   67.000000  6.2  103.000000        0.0\n",
              "5205       1   77  34.8  104.700000  ...  117.000000  5.7   96.866305        1.0\n",
              "\n",
              "[5206 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5rKM18Sdsz2"
      },
      "source": [
        "# PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmAmAPI_VbPk",
        "outputId": "7dfcdf5d-dd48-44b7-b988-63a8bcd207cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = data.iloc[:, 0:12].values\n",
        "y = data.iloc[:, 12].values\n",
        "x\n",
        "y"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNDpCTFDhtpL"
      },
      "source": [
        "ynew=[]\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKBDMnfbhkVe",
        "outputId": "49869ef7-fbb7-46b9-df99-90ca055fec78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in y:\n",
        "  if i>0.5:\n",
        "    add=1\n",
        "    ynew.append(add)\n",
        "  elif i<0.5:\n",
        "    add=0\n",
        "    ynew.append(add)\n",
        "\n",
        "ynew\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_XV2oo6AvhO"
      },
      "source": [
        "#gender\tage Trigs\tbmi\twaist_cm\tsys_bp\tdia_bp\talb_cr_ratio\tt_chol\tglucose\ta1c\tglucose.1\tDiabetes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCwPdtH0CocU"
      },
      "source": [
        "Gender: prediabetes=47.8% (of 226), Diabetes = 52% (of 275)\n",
        "Age: prediabetes = (60)34-85, Diabetes= (64)24-84yrs\n",
        "Trigs: Normal = 0.1-0.7, Pre=(1.3) 0.5-5.3, Diabetes =(1.5) 0.4-7.7\n",
        "BMI:normal = 28 ± 3, pre= \t29 ± 1\n",
        "Waist_cm:normal = 89 ± 5, pre=\t99 ± 2\n",
        "sys_bp:normal=120 ± 4,pre=\t131 ± 7\n",
        "dia_bp:normal =74 ± 1,\t77 ± 4\n",
        "(serum)glucose.1:pre=140-200\n",
        "(serum) glucose: normal=<140, pre=140-199, diabetes> 200\n",
        "\n",
        "alb_cr_ratio:pre=9.6 (2.3–730.7),dia =\t15.8 (2.4–1,242.7)\n",
        "t_chol:Normal = 2.6–5.2,pre=(5.4) 2.9–8.9, (4.6)2.5–7.5\t\n",
        "(fasting)glucose:Norm=3.9–5.5,Pre=5.9(4.2–6.9),Dia=7.7(3.6–21.3)\n",
        "fasting glucose: normal=95 ± 10,prediabetes:\t101 ± 2\n",
        "fasting = normal < 100, pre=100-125, diabetes>126\n",
        "A1C:normal= 4-5.6, pre=(5.7) 4.5–8.0, dia=(7)4.5–8.0\n",
        "\n",
        "https://www.mayoclinic.org/diseases-conditions/diabetes/diagnosis-treatment/drc-20371451#:~:text=A%20fasting%20blood%20sugar%20level,Oral%20glucose%20tolerance%20test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJDzNR4BS7Ur"
      },
      "source": [
        "# Feature1: Fasting Glucose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DunEZVnBP1r8"
      },
      "source": [
        "data['Glucose_Output'] = data['glucose'].apply(lambda x: 'diabetes' if x > 125 else 'prediabetes' if x > 99 and x <= 125 else 'normal' if x > 70 else 'diabetes')\n",
        "data.head()\n",
        "  \n",
        "#normal=0, prediabetes=2, diabetes=1\n",
        "data['Glucose_Output'] = data['Glucose_Output'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "data.head()\n",
        "data.to_csv('feature1.csv',index=False, header=True)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWLp9ilEVLDh",
        "outputId": "07e2e4ba-b671-42cb-924e-f97dae5d735e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "data1 = pd.read_csv('feature1.csv')\n",
        "data1.head()\n",
        "data1 = data1[['glucose','Glucose_Output']]\n",
        "data1.head()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>glucose</th>\n",
              "      <th>Glucose_Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>87.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>89.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   glucose  Glucose_Output\n",
              "0     82.0               0\n",
              "1     81.0               0\n",
              "2     87.0               0\n",
              "3     91.0               0\n",
              "4     89.0               0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5k6WXh9X5tw",
        "outputId": "04848ac5-d297-4f46-e9da-3b9de223f8da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "data1.to_csv('Feature1.csv', index=False)\n",
        "data1\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>glucose</th>\n",
              "      <th>Glucose_Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>87.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>89.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>126.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>91.927995</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>101.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>103.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>93.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         glucose  Glucose_Output\n",
              "0      82.000000               0\n",
              "1      81.000000               0\n",
              "2      87.000000               0\n",
              "3      91.000000               0\n",
              "4      89.000000               0\n",
              "...          ...             ...\n",
              "5201  126.000000               1\n",
              "5202   91.927995               0\n",
              "5203  101.000000               2\n",
              "5204  103.000000               2\n",
              "5205   93.000000               0\n",
              "\n",
              "[5206 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwQn_tebY71m",
        "outputId": "3e011a88-99fa-4119-c5c7-ce3bba61f78e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "x1 = data1.iloc[:, 0:1].values\n",
        "y1 = data1.iloc[:, 1].values\n",
        "y1\n",
        "x1"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 82.],\n",
              "       [ 81.],\n",
              "       [ 87.],\n",
              "       ...,\n",
              "       [101.],\n",
              "       [103.],\n",
              "       [ 93.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX_-ArVXeuNg",
        "outputId": "5c78000e-e115-4d0f-c664-9aba3726f62a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x1.shape)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5206, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOmhbtjwYI-w"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-gHaELsYRAF",
        "outputId": "d132539c-4aee-4055-f0e5-f4037f645a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "splitRatio = 0.01\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x1,y1,test_size = splitRatio)\n",
        "x_train"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 87.],\n",
              "       [ 85.],\n",
              "       [ 91.],\n",
              "       ...,\n",
              "       [160.],\n",
              "       [ 85.],\n",
              "       [ 99.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKto4i_SYVJY"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression \n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp_cOVQBYYKE",
        "outputId": "e9075af0-8ee6-4cda-edc6-684c01205fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model =  LogisticRegression()\n",
        "model.fit(x1,y1)\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J2r00NHZa55",
        "outputId": "ba636702-bace-40e4-8589-32b9dff509b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "prediction = model.predict_proba(x1)\n",
        "prediction"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.95963746, 0.0030454 , 0.03731714],\n",
              "       [0.9660719 , 0.00245571, 0.03147239],\n",
              "       [0.90591345, 0.00871909, 0.08536746],\n",
              "       ...,\n",
              "       [0.42763043, 0.09196545, 0.48040412],\n",
              "       [0.34061616, 0.11417215, 0.54521169],\n",
              "       [0.76393027, 0.02783906, 0.20823068]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa6RPOJ0oHYv",
        "outputId": "846364a7-1eed-444e-bd1c-c157c0d1e4a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y1"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 2, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmWBshIAanJw"
      },
      "source": [
        "#predictionGlucose = prediction.astype(int)\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_UrjHKlatzO"
      },
      "source": [
        "outGlucose=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "outGlucose.to_csv('glucosePredictions.csv',index=False, header=True)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnus0UzLb9tB",
        "outputId": "70614563-917e-46a9-8dfe-979b17563ec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "gluout = pd.read_csv('glucosePredictions.csv')\n",
        "gluout\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.959637</td>\n",
              "      <td>0.003045</td>\n",
              "      <td>0.037317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.966072</td>\n",
              "      <td>0.002456</td>\n",
              "      <td>0.031472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.905913</td>\n",
              "      <td>0.008719</td>\n",
              "      <td>0.085367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.823257</td>\n",
              "      <td>0.019249</td>\n",
              "      <td>0.157494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.870119</td>\n",
              "      <td>0.013053</td>\n",
              "      <td>0.116828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0.006664</td>\n",
              "      <td>0.367731</td>\n",
              "      <td>0.625604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0.797328</td>\n",
              "      <td>0.022905</td>\n",
              "      <td>0.179767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0.427630</td>\n",
              "      <td>0.091965</td>\n",
              "      <td>0.480404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>0.340616</td>\n",
              "      <td>0.114172</td>\n",
              "      <td>0.545212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>0.763930</td>\n",
              "      <td>0.027839</td>\n",
              "      <td>0.208231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2\n",
              "0     0.959637  0.003045  0.037317\n",
              "1     0.966072  0.002456  0.031472\n",
              "2     0.905913  0.008719  0.085367\n",
              "3     0.823257  0.019249  0.157494\n",
              "4     0.870119  0.013053  0.116828\n",
              "...        ...       ...       ...\n",
              "5201  0.006664  0.367731  0.625604\n",
              "5202  0.797328  0.022905  0.179767\n",
              "5203  0.427630  0.091965  0.480404\n",
              "5204  0.340616  0.114172  0.545212\n",
              "5205  0.763930  0.027839  0.208231\n",
              "\n",
              "[5206 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igg9l8LHdfK6"
      },
      "source": [
        "# Feature 2: Age"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tP3BRJYeHRe"
      },
      "source": [
        "Age: prediabetes = (60)34-85, Diabetes= (64)24-84yrs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEqVAbdUcP2e"
      },
      "source": [
        "data['AgeOutput'] = data['age'].apply(lambda x: 'diabetes' if 45 <= x  else 'prediabetes' if x >= 25 and x <= 44 else 'normal' if x < 25 else 'diabetes')\n",
        "data.head()\n",
        "  \n",
        "#normal=0, prediabetes=2, diabetes=1\n",
        "data['AgeOutput'] = data['AgeOutput'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "data.head()\n",
        "data.to_csv('feature2.csv',index=False, header=True)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGWhGbmKjcqX",
        "outputId": "bd7b9266-caf9-4200-d45e-31754edfca38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "dataread = pd.read_csv('feature2.csv')\n",
        "dataread\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>dia_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>glucose</th>\n",
              "      <th>trigs</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>Diabetes</th>\n",
              "      <th>AgeOutput</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>50.00000</td>\n",
              "      <td>11.77</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.700000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>60.00000</td>\n",
              "      <td>2.37</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.300000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>72.00000</td>\n",
              "      <td>3.73</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>94.160745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.100000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>3.74</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.600000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>64.00000</td>\n",
              "      <td>3.13</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.900000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>64.00000</td>\n",
              "      <td>11.43</td>\n",
              "      <td>171.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.200000</td>\n",
              "      <td>140.666578</td>\n",
              "      <td>76.05274</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>207.939424</td>\n",
              "      <td>91.927995</td>\n",
              "      <td>205.687652</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>39.2</td>\n",
              "      <td>128.090281</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>33.20</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>6.3</td>\n",
              "      <td>106.720790</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.500000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>74.00000</td>\n",
              "      <td>3.92</td>\n",
              "      <td>181.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.700000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>78.00000</td>\n",
              "      <td>4.16</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>5.7</td>\n",
              "      <td>96.866305</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  age   bmi    waist_cm  ...  a1c   glucose.1  Diabetes   AgeOutput\n",
              "0          1   21  18.2   82.000000  ...  5.0   88.000000        0.0          0\n",
              "1          0   21  25.9   93.700000  ...  5.2   88.000000        0.0          0\n",
              "2          0   21  29.5  102.300000  ...  5.1   94.160745        0.0          0\n",
              "3          0   21  17.9   69.100000  ...  5.1   95.000000        0.0          0\n",
              "4          0   21  30.6  101.600000  ...  6.0   95.000000        0.0          0\n",
              "...      ...  ...   ...         ...  ...  ...         ...        ...        ...\n",
              "5201       0   77  32.8  115.900000  ...  6.5  134.000000        1.0          1\n",
              "5202       0   77  32.9  122.200000  ...  6.2   98.000000        0.0          1\n",
              "5203       0   77  39.2  128.090281  ...  6.3  106.720790        1.0          1\n",
              "5204       1   77  36.5  119.500000  ...  6.2  103.000000        0.0          1\n",
              "5205       1   77  34.8  104.700000  ...  5.7   96.866305        1.0          1\n",
              "\n",
              "[5206 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY95ocu9kHCp",
        "outputId": "6ee9a87b-7ffe-4f6d-a300-c613bb6288ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "data2 = pd.read_csv('feature2.csv')\n",
        "data2.head()\n",
        "data2 = data2[['age','AgeOutput']]\n",
        "data2.head()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>AgeOutput</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  AgeOutput\n",
              "0   21          0\n",
              "1   21          0\n",
              "2   21          0\n",
              "3   21          0\n",
              "4   21          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bp4x5vSkUrQ",
        "outputId": "a32e2b8e-c2c0-4032-fd52-03a6680cea4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "data2.to_csv('Feature2.csv', index=False)\n",
        "data2\n"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>AgeOutput</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  AgeOutput\n",
              "0      21          0\n",
              "1      21          0\n",
              "2      21          0\n",
              "3      21          0\n",
              "4      21          0\n",
              "...   ...        ...\n",
              "5201   77          1\n",
              "5202   77          1\n",
              "5203   77          1\n",
              "5204   77          1\n",
              "5205   77          1\n",
              "\n",
              "[5206 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo_v9LPkkl14",
        "outputId": "ec1b8a78-bde0-4d32-a013-7ecc32c9798b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x2 = data2.iloc[:, 0:1].values\n",
        "y2 = data2.iloc[:, 1].values\n",
        "y2"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7OsEtSNmFWo",
        "outputId": "0e496f1c-f26f-47c7-b66b-3f02b48ecd6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model =  LogisticRegression()\n",
        "model.fit(x2,y2)\n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hypWkLYMmFcO"
      },
      "source": [
        "prediction = model.predict_proba(x2)\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d-bTuOEmFQM"
      },
      "source": [
        "outAge=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "outAge.to_csv('AgePredictions.csv',index=False, header=True)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYL7eXZLJXrd"
      },
      "source": [
        "Try RANDOM FOREST also"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5vaJopZBJuM"
      },
      "source": [
        "# feature 3: BMI "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta_zrioiCBUy"
      },
      "source": [
        "data = pd.read_csv(r'miceDataset.csv')"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdVUV1-BN2d"
      },
      "source": [
        "data['BMI_Output'] = data['bmi'].apply(lambda x: 'diabetes' if x >= 30 else 'prediabetes' if x > 24 and x < 30 else 'normal' if x < 25 else 'diabetes')\n",
        "data.head()\n",
        "  \n",
        "#normal=0, prediabetes=2, diabetes=1\n",
        "data['BMI_Output'] = data['BMI_Output'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "data.head()\n",
        "data.to_csv('feature3.csv',index=False, header=True)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyaP7ZwkBN0V",
        "outputId": "6a9e37fb-b56a-4180-9804-54aa0fe1573b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "data3 = pd.read_csv('feature3.csv')\n",
        "\n",
        "data3 = data3[['bmi','BMI_Output']]\n",
        "data3.head()"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bmi</th>\n",
              "      <th>BMI_Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29.5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    bmi  BMI_Output\n",
              "0  18.2           0\n",
              "1  25.9           2\n",
              "2  29.5           2\n",
              "3  17.9           0\n",
              "4  30.6           1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr9Cld5CBNyg",
        "outputId": "9ba773ed-66df-4246-c527-fcdce17ea749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "x3 = data1.iloc[:, 0:1].values\n",
        "y3 = data1.iloc[:, 1].values\n",
        "y3\n",
        "x3"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 82.],\n",
              "       [ 81.],\n",
              "       [ 87.],\n",
              "       ...,\n",
              "       [101.],\n",
              "       [103.],\n",
              "       [ 93.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM-2nnO0BNvn",
        "outputId": "462281ea-261c-4daf-f511-4e796c1a0a9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model =  LogisticRegression()\n",
        "model.fit(x3,y3)\n"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUvIM380BNtE"
      },
      "source": [
        "prediction = model.predict_proba(x3)\n"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40eaD9Y7BNqS"
      },
      "source": [
        "outbmi=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "outbmi.to_csv('BMIPredictions.csv',index=False, header=True)"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciHzVK5EMgWN"
      },
      "source": [
        "# Feature 4: Sys_BP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-8PFV4pMxBN"
      },
      "source": [
        "sys_bp:normal=<124,pre=124-138, diabetes >139"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMqs_snmMus_"
      },
      "source": [
        "data['SysOutput'] = data['sys_bp'].apply(lambda x: 'diabetes' if x > 138 else 'prediabetes' if x > 123 and x <= 138 else 'normal' if x <124 else 'diabetes')\n",
        "data.head()\n",
        "  \n",
        "#normal=0, prediabetes=2, diabetes=1\n",
        "data['SysOutput'] = data['SysOutput'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "data.head()\n",
        "data.to_csv('feature4.csv',index=False, header=True)"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REbrJVzgMu3y",
        "outputId": "5508d6c4-fc3f-4053-8ef0-8b3b1eabd93a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "data4 = pd.read_csv('feature4.csv')\n",
        "data4.head()\n",
        "data4 = data4[['sys_bp','SysOutput']]\n",
        "data4.head()"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>SysOutput</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>114.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>108.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sys_bp  SysOutput\n",
              "0    96.0          0\n",
              "1   110.0          0\n",
              "2   114.0          0\n",
              "3   108.0          0\n",
              "4   134.0          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKh05qp4Mu1X",
        "outputId": "c287f6ce-aec9-462a-ee44-622d2c919473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "data4.to_csv('Feature4.csv', index=False)\n",
        "data4\n"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>SysOutput</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>114.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>108.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>130.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>140.666578</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>136.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>128.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          sys_bp  SysOutput\n",
              "0      96.000000          0\n",
              "1     110.000000          0\n",
              "2     114.000000          0\n",
              "3     108.000000          0\n",
              "4     134.000000          2\n",
              "...          ...        ...\n",
              "5201  130.000000          2\n",
              "5202  140.666578          1\n",
              "5203  136.000000          2\n",
              "5204  128.000000          2\n",
              "5205  150.000000          1\n",
              "\n",
              "[5206 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oXu-pPGMupr",
        "outputId": "c2198dd2-9a52-4683-d7e5-6054d1f282be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "x4 = data4.iloc[:, 0:1].values\n",
        "y4 = data4.iloc[:, 1].values\n",
        "y4\n",
        "x4"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 96.],\n",
              "       [110.],\n",
              "       [114.],\n",
              "       ...,\n",
              "       [136.],\n",
              "       [128.],\n",
              "       [150.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcR-WAL3Munb",
        "outputId": "efb86700-a9b1-4e38-fbb8-b9e7a3a8b451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "model =  LogisticRegression()\n",
        "model.fit(x4,y4)\n",
        "prediction = model.predict_proba(x4)\n",
        "prediction\n"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.00000000e+000, 2.12373863e-128, 3.64579538e-058],\n",
              "       [1.00000000e+000, 1.23539583e-075, 2.19943562e-028],\n",
              "       [1.00000000e+000, 1.47040221e-060, 7.09628349e-020],\n",
              "       ...,\n",
              "       [2.24387606e-028, 2.71894305e-005, 9.99972811e-001],\n",
              "       [2.33587759e-011, 1.99798071e-018, 1.00000000e+000],\n",
              "       [1.41871019e-076, 1.00000000e+000, 3.81418698e-019]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKrSPNJUMulF"
      },
      "source": [
        "outsysbp=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "outsysbp.to_csv('sysBPPredictions.csv',index=False, header=True)"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiwDHTpfQXXC"
      },
      "source": [
        "# Feature 5: Diastolic BP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUs1KNpVRBOE"
      },
      "source": [
        "dia_bp:normal =74 ± 1, 77 ± 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym6EIpMMUJ6A",
        "outputId": "f8dbb3fc-e098-4036-9b7e-4c46349c2037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = pd.read_csv(r'miceDataset.csv')\n",
        "x = data.iloc[:, 0:12].values\n",
        "y = data.iloc[:, 12].values\n",
        "x\n",
        "y\n"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kriz_yErMuin"
      },
      "source": [
        "data['diasOut'] = data['dia_bp'].apply(lambda x: 'diabetes' if x>81 else 'prediabetes' if x <81 and x >75 else 'normal' if x <= 75 else 'diabetes')\n",
        "data.head()\n",
        "  \n",
        "#normal=0, prediabetes=2, diabetes=1\n",
        "data['diasOut'] = data['diasOut'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "data.head()\n",
        "data.to_csv('feature5.csv',index=False, header=True)\n",
        "data5 = pd.read_csv('feature5.csv')\n",
        "data5 = data5[['dia_bp','diasOut']]\n",
        "data5.head()\n",
        "data5.to_csv('Feature5.csv', index=False)\n",
        "data5\n",
        "x5 = data5.iloc[:, 0:1].values\n",
        "y5 = data5.iloc[:, 1].values\n",
        "y5\n",
        "model =  LogisticRegression()\n",
        "model.fit(x5,y5)\n",
        "prediction = model.predict_proba(x5)\n",
        "dias=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "dias.to_csv('diasBPPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8Xd2OEuTTC5"
      },
      "source": [
        "# Feature 6: alb_cr_ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91rBbZq7VWNn"
      },
      "source": [
        "pre=9.6 (2.3–730.7),dia =\t15.8 (2.4–1,242.7)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP4XlroITi1c"
      },
      "source": [
        "data['albOut'] = data['alb_cr_ratio'].apply(lambda x: 'diabetes' if  x>30  else 'prediabetes' if x >=3 and x <30 else 'normal' if x <3 else 'diabetes')  \n",
        "\n",
        "data['albOut'] = data['albOut'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature6.csv',index=False, header=True)\n",
        "\n",
        "data6 = pd.read_csv('feature6.csv')\n",
        "data6 = data6[['alb_cr_ratio','albOut']]\n",
        "data6.to_csv('Feature6.csv', index=False)\n",
        "\n",
        "x6 = data6.iloc[:, 0:1].values\n",
        "y6 = data6.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x6,y6)\n",
        "prediction = model.predict_proba(x6)\n",
        "alb=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "alb.to_csv('albcrPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b1eQawPVixq"
      },
      "source": [
        "# Feature 7: WAIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOCsnCvTdezb"
      },
      "source": [
        "normal =89 ± 5, pre=\t99 ± 2,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqR-ItbrWp1Q"
      },
      "source": [
        "data['waist'] = data['waist_cm'].apply(lambda x: 'diabetes' if 101 < x  else 'prediabetes' if x >94 and x <=101 else 'normal' if x <=94 else 'diabetes')  \n",
        "\n",
        "data['waist'] = data['waist'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature7.csv',index=False, header=True)\n",
        "\n",
        "data7 = pd.read_csv('feature7.csv')\n",
        "data7 = data7[['waist_cm','waist']]\n",
        "data7.to_csv('Feature7.csv', index=False)\n",
        "\n",
        "x7 = data7.iloc[:, 0:1].values\n",
        "y7 = data7.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x7,y7)\n",
        "prediction = model.predict_proba(x7)\n",
        "wai=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "wai.to_csv('waistPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MOMgbGZWtmU"
      },
      "source": [
        "# Feature 8:A1C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TszUvYSeMqV"
      },
      "source": [
        "A1C:normal= 4-5.6, pre=(5.7) 4.5–8.0, dia=(7)4.5–8.0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMioyIJwXMwu"
      },
      "source": [
        "data['haemo'] = data['a1c'].apply(lambda x: 'diabetes' if  x>=6.5  else 'prediabetes' if x >=5.7 and x <6.5 else 'normal' if x<5.7 else 'diabetes')  \n",
        "\n",
        "data['haemo'] = data['haemo'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature8.csv',index=False, header=True)\n",
        "\n",
        "data8 = pd.read_csv('feature8.csv')\n",
        "data8 = data8[['a1c','haemo']]\n",
        "data8.to_csv('Feature8.csv', index=False)\n",
        "\n",
        "x8 = data8.iloc[:, 0:1].values\n",
        "y8 = data8.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x8,y8)\n",
        "prediction = model.predict_proba(x8)\n",
        "hg=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "hg.to_csv('a1cPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x2J67bZWyT8"
      },
      "source": [
        "# Feature 9: Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJG0hP10XNym"
      },
      "source": [
        "data['gen'] = data['gender'].apply(lambda x: 'diabetes' if 81 <= x  else 'prediabetes' if x >=81 and x <75 else 'normal' if x <= 75 else 'diabetes')  \n",
        "\n",
        "data['gen'] = data['gen'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature9.csv',index=False, header=True)\n",
        "\n",
        "data9 = pd.read_csv('feature9.csv')\n",
        "data9 = data9[['gender','gen']]\n",
        "data9.to_csv('Feature9.csv', index=False)\n",
        "\n",
        "x9 = data9.iloc[:, 0:1].values\n",
        "y9 = data9.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x9,y9)\n",
        "prediction = model.predict_proba(x9)\n",
        "g=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "g.to_csv('genderPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjuapIIAW3SU"
      },
      "source": [
        "#Feature 10: Trigs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW-3zl3jfHJM"
      },
      "source": [
        "Normal = 0.1-0.7, Pre=(1.3) 0.5-5.3, Diabetes =(1.5) 0.4-7.7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL4NyeiNXO19"
      },
      "source": [
        "data['Tri'] = data['trigs'].apply(lambda x: 'diabetes' if 200<= x  else 'prediabetes' if x >=150 and x <200 else 'normal' if x <150 else 'diabetes')  \n",
        "\n",
        "data['Tri'] = data['Tri'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature10.csv',index=False, header=True)\n",
        "\n",
        "data10 = pd.read_csv('feature10.csv')\n",
        "data10 = data10[['trigs','Tri']]\n",
        "data10.to_csv('Feature10.csv', index=False)\n",
        "\n",
        "x10 = data10.iloc[:, 0:1].values\n",
        "y10 = data10.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x10,y10)\n",
        "prediction = model.predict_proba(x10)\n",
        "gly=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "gly.to_csv('triglyPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRDKorWNW790"
      },
      "source": [
        "# Feature 11: t_chol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CPX1DPsgEHc"
      },
      "source": [
        "t_chol:Normal = 2.6–5.2,pre=(5.4) 2.9–8.9, (4.6)2.5–7.5\t\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAps5gPhXPz_"
      },
      "source": [
        "data['chol'] = data['t_chol'].apply(lambda x: 'diabetes' if 240 <= x  else 'prediabetes' if x >=200 and x <240 else 'normal' if x <200 else 'diabetes')  \n",
        "\n",
        "data['chol'] = data['chol'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature11.csv',index=False, header=True)\n",
        "\n",
        "data11 = pd.read_csv('feature11.csv')\n",
        "data11 = data11[['t_chol','chol']]\n",
        "data11.to_csv('Feature11.csv', index=False)\n",
        "\n",
        "x11 = data11.iloc[:, 0:1].values\n",
        "y11 = data11.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x11,y11)\n",
        "prediction = model.predict_proba(x11)\n",
        "choles=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "choles.to_csv('CholesPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eRzB19vXAMu"
      },
      "source": [
        "# Feature 12: Serum Glucose\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYeUTIYrXQ3b"
      },
      "source": [
        "data['serum'] = data['glucose.1'].apply(lambda x: 'diabetes' if 200 <= x  else 'prediabetes' if x >=140 and x <200 else 'normal' if x<140 else 'diabetes')  \n",
        "\n",
        "data['serum'] = data['serum'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature12.csv',index=False, header=True)\n",
        "\n",
        "data12 = pd.read_csv('feature12.csv')\n",
        "data12 = data12[['glucose.1','serum']]\n",
        "data12.to_csv('Feature12.csv', index=False)\n",
        "\n",
        "x12 = data12.iloc[:, 0:1].values\n",
        "y12 = data12.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x12,y12)\n",
        "prediction = model.predict_proba(x12)\n",
        "ser=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "ser.to_csv('SerumGluPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij0eXVcEuTwQ"
      },
      "source": [
        "# Determination of weights by Tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLTgH3Tlv-L_"
      },
      "source": [
        "feature weights\n",
        "https://scikit-learn.org/stable/modules/feature_extraction.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjLdfPb-vUiy"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vflFvUGWvUu8"
      },
      "source": [
        "transformer = TfidfTransformer(smooth_idf=False)\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrL6G96WvUy2"
      },
      "source": [
        "tfidf = transformer.fit_transform(x,y)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPelE8jgvUtF",
        "outputId": "e3853e6c-bb6f-45fd-d3c5-88a27bee5957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "tfidf.toarray()\n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00744823, 0.09326155, 0.08082667, ..., 0.2398154 , 0.02220513,\n",
              "        0.39081029],\n",
              "       [0.        , 0.07596254, 0.09368713, ..., 0.30023288, 0.01880977,\n",
              "        0.3183192 ],\n",
              "       [0.        , 0.05607968, 0.0787786 , ..., 0.683638  , 0.01361935,\n",
              "        0.25145259],\n",
              "       ...,\n",
              "       [0.        , 0.2085349 , 0.10616322, ..., 0.45769349, 0.01706195,\n",
              "        0.2890261 ],\n",
              "       [0.00525231, 0.24114128, 0.11430723, ..., 0.20982423, 0.01941657,\n",
              "        0.3225656 ],\n",
              "       [0.00468357, 0.21502954, 0.09718218, ..., 0.3267332 , 0.01591777,\n",
              "        0.27050802]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LgdZIYfw35v"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVFOIjNRw1pR"
      },
      "source": [
        "data = pd.read_csv(r'miceDataset.csv')"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibGiRfGjxaLs",
        "outputId": "a6d6964c-5865-40fb-e2fb-6f2d0419cdff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = data.iloc[:, 0:12].values\n",
        "y = data.iloc[:, 12].values\n",
        "x\n",
        "y"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6PjdnGLxcET"
      },
      "source": [
        "ynew=[]\n",
        "\n"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtFC3qczxhET",
        "outputId": "8455c3ea-4156-43cc-ae8a-edf30a3152ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in y:\n",
        "  if i>0.5:\n",
        "    add=1\n",
        "    ynew.append(add)\n",
        "  elif i<0.5:\n",
        "    add=0\n",
        "    ynew.append(add)\n",
        "\n",
        "ynew\n"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN_GgzzMx10U"
      },
      "source": [
        "from matplotlib import pyplot\n"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qePm5PmQw82d",
        "outputId": "ad156195-ddf2-4f45-f4f1-13cef20856e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "model = LinearRegression()\n",
        "# fit the model\n",
        "model.fit(x, ynew)\n",
        "# get importance\n",
        "importance = model.coef_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
        "# plot feature importance\n",
        "pyplot.bar([j for j in range(len(importance))], importance)\n",
        "pyplot.show()"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature: 0, Score: 0.01521\n",
            "Feature: 1, Score: 0.00135\n",
            "Feature: 2, Score: -0.00028\n",
            "Feature: 3, Score: 0.00181\n",
            "Feature: 4, Score: 0.00084\n",
            "Feature: 5, Score: -0.00098\n",
            "Feature: 6, Score: -0.00002\n",
            "Feature: 7, Score: -0.00127\n",
            "Feature: 8, Score: 0.00097\n",
            "Feature: 9, Score: 0.00011\n",
            "Feature: 10, Score: 0.18929\n",
            "Feature: 11, Score: -0.00034\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hurEpxnZw8yF"
      },
      "source": [
        "label=['gender',\t'age',\t'bmi',\t'waist_cm',\t'sys_bp',\t'dia_bp',\t'alb_cr_ratio',\t\t't_chol',\t\t'glucose',\t'trigs',\t'a1c',\t'glucose.1'\t]"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPHZijUVyiM-",
        "outputId": "3df8088f-e92f-4312-d803-2188295e19a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, ynew, test_size=0.2)\n",
        "# Preprocessing\n",
        "########################## try without splitting the data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RFclassifier = RandomForestClassifier(n_estimators = 100,random_state=0,warm_start=True)\n",
        "RFclassifier.fit(x_train, y_train)\n",
        "y_pred = RFclassifier.predict(x_test)\n",
        "  #print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       913\n",
            "           1       0.97      0.83      0.90       129\n",
            "\n",
            "    accuracy                           0.98      1042\n",
            "   macro avg       0.97      0.91      0.94      1042\n",
            "weighted avg       0.98      0.98      0.98      1042\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpyWqitp4A-T"
      },
      "source": [
        "\n",
        "import pickle\n",
        "filename = 'RF.pkl'\n",
        "pickle.dump(RFclassifier, open(filename, 'wb'))"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR9hL9m8w8wg",
        "outputId": "d0a645d7-90b1-42e1-d17d-48d3bbad2229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        }
      },
      "source": [
        "def plot_feature_importance(importance,names,model_type):\n",
        "  feature_importance = np.array(importance)\n",
        "  feature_names = np.array(names)\n",
        " \n",
        "#Create a DataFrame using a Dictionary\n",
        "  data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
        "  fi_df = pd.DataFrame(data)\n",
        " \n",
        "#Sort the DataFrame in order decreasing feature importance\n",
        "  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
        "  #Define size of bar plot\n",
        "  plt.figure(figsize=(10,8))\n",
        "#Plot Searborn bar chart\n",
        "  sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
        "#Add chart labels\n",
        "  plt.title(model_type + ' FEATURE IMPORTANCE')\n",
        "  plt.xlabel('FEATURE IMPORTANCE')\n",
        "  plt.ylabel('FEATURE NAMES')\n",
        "\n",
        "plot_feature_importance(RFclassifier.feature_importances_,label,'RANDOM FOREST')\n",
        "weight =RFclassifier.feature_importances_\n",
        "print(weight)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00320898 0.02742387 0.0212766  0.02955473 0.01910558 0.01670827\n",
            " 0.03682936 0.03118109 0.1102987  0.02109187 0.52586535 0.1574556 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CH8VCNN8C_z",
        "outputId": "b5432076-9757-450e-f94a-013a8a652165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weight[8]\n",
        "weight[1]"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.027423867439744707"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC50Oh3p1b-i"
      },
      "source": [
        "# Thresholding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5M9unKu1fWl",
        "outputId": "f1d1d526-fb4a-46b1-dfe7-118d6453f533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "glucose = pd.read_csv('glucosePredictions.csv')\n",
        "glucose\n"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.959637</td>\n",
              "      <td>0.003045</td>\n",
              "      <td>0.037317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.966072</td>\n",
              "      <td>0.002456</td>\n",
              "      <td>0.031472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.905913</td>\n",
              "      <td>0.008719</td>\n",
              "      <td>0.085367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.823257</td>\n",
              "      <td>0.019249</td>\n",
              "      <td>0.157494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.870119</td>\n",
              "      <td>0.013053</td>\n",
              "      <td>0.116828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0.006664</td>\n",
              "      <td>0.367731</td>\n",
              "      <td>0.625604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0.797328</td>\n",
              "      <td>0.022905</td>\n",
              "      <td>0.179767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0.427630</td>\n",
              "      <td>0.091965</td>\n",
              "      <td>0.480404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>0.340616</td>\n",
              "      <td>0.114172</td>\n",
              "      <td>0.545212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>0.763930</td>\n",
              "      <td>0.027839</td>\n",
              "      <td>0.208231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2\n",
              "0     0.959637  0.003045  0.037317\n",
              "1     0.966072  0.002456  0.031472\n",
              "2     0.905913  0.008719  0.085367\n",
              "3     0.823257  0.019249  0.157494\n",
              "4     0.870119  0.013053  0.116828\n",
              "...        ...       ...       ...\n",
              "5201  0.006664  0.367731  0.625604\n",
              "5202  0.797328  0.022905  0.179767\n",
              "5203  0.427630  0.091965  0.480404\n",
              "5204  0.340616  0.114172  0.545212\n",
              "5205  0.763930  0.027839  0.208231\n",
              "\n",
              "[5206 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En0X8sIy2mQu"
      },
      "source": [
        "G0=glucose.iloc[:,0]\n",
        "G1=glucose.iloc[:,1]\n",
        "G2=glucose.iloc[:,2]\n"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYR0ovpd1fTt",
        "outputId": "a5c96462-36b0-4aa6-dc7d-af5432de5e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "Age = pd.read_csv('AgePredictions.csv')\n",
        "Age\n"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.299464e-63</td>\n",
              "      <td>1.930293e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.299464e-63</td>\n",
              "      <td>1.930293e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.299464e-63</td>\n",
              "      <td>1.930293e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.299464e-63</td>\n",
              "      <td>1.930293e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.299464e-63</td>\n",
              "      <td>1.930293e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>6.213459e-205</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.776281e-75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>6.213459e-205</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.776281e-75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>6.213459e-205</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.776281e-75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>6.213459e-205</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.776281e-75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>6.213459e-205</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.776281e-75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0             1             2\n",
              "0      1.000000e+00  5.299464e-63  1.930293e-09\n",
              "1      1.000000e+00  5.299464e-63  1.930293e-09\n",
              "2      1.000000e+00  5.299464e-63  1.930293e-09\n",
              "3      1.000000e+00  5.299464e-63  1.930293e-09\n",
              "4      1.000000e+00  5.299464e-63  1.930293e-09\n",
              "...             ...           ...           ...\n",
              "5201  6.213459e-205  1.000000e+00  7.776281e-75\n",
              "5202  6.213459e-205  1.000000e+00  7.776281e-75\n",
              "5203  6.213459e-205  1.000000e+00  7.776281e-75\n",
              "5204  6.213459e-205  1.000000e+00  7.776281e-75\n",
              "5205  6.213459e-205  1.000000e+00  7.776281e-75\n",
              "\n",
              "[5206 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6jJ3YKI1fSK"
      },
      "source": [
        "A0=Age.iloc[:,0]\n",
        "A1=Age.iloc[:,1]\n",
        "A2=Age.iloc[:,2]\n"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnRA_0pYj2iJ"
      },
      "source": [
        "bmi = pd.read_csv('BMIPredictions.csv')\n",
        "bmi\n",
        "\n",
        "B0=bmi.iloc[:,0]\n",
        "B1=bmi.iloc[:,1]\n",
        "B2=bmi.iloc[:,2]\n"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OvrGTlOmNak"
      },
      "source": [
        "wai = pd.read_csv('waistPredictions.csv')\n",
        "wai\n",
        "\n",
        "W0=wai.iloc[:,0]\n",
        "W1=wai.iloc[:,1]\n",
        "W2=wai.iloc[:,2]\n"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WK58shcmZnX"
      },
      "source": [
        "sys = pd.read_csv('sysBPPredictions.csv')\n",
        "sys\n",
        "\n",
        "S0=sys.iloc[:,0]\n",
        "S1=sys.iloc[:,1]\n",
        "S2=sys.iloc[:,2]\n"
      ],
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCnCZF_jmjM5"
      },
      "source": [
        "dia = pd.read_csv('diasBPPredictions.csv')\n",
        "dia\n",
        "\n",
        "D0=dia.iloc[:,0]\n",
        "D1=dia.iloc[:,1]\n",
        "D2=dia.iloc[:,2]\n"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7eq6qyymtHi"
      },
      "source": [
        "ratio = pd.read_csv('albcrPredictions.csv')\n",
        "ratio\n",
        "\n",
        "alb0=ratio.iloc[:,0]\n",
        "alb1=ratio.iloc[:,1]\n",
        "alb2=ratio.iloc[:,2]\n"
      ],
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhvv0f9rm6k1"
      },
      "source": [
        "chol = pd.read_csv('CholesPredictions.csv')\n",
        "chol\n",
        "\n",
        "C0=chol.iloc[:,0]\n",
        "C1=chol.iloc[:,1]\n",
        "C2=chol.iloc[:,2]\n"
      ],
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ft7PFq6nFNK"
      },
      "source": [
        "tr = pd.read_csv('triglyPredictions.csv')\n",
        "tr\n",
        "\n",
        "T0=tr.iloc[:,0]\n",
        "T1=tr.iloc[:,1]\n",
        "T2=tr.iloc[:,2]\n"
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCZDK2hhnUNj"
      },
      "source": [
        "a1c = pd.read_csv('a1cPredictions.csv')\n",
        "a1c\n",
        "\n",
        "a1c0=a1c.iloc[:,0]\n",
        "a1c1=a1c.iloc[:,1]\n",
        "a1c2=a1c.iloc[:,2]\n"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd8hMcFfngr-"
      },
      "source": [
        "pl = pd.read_csv('SerumGluPredictions.csv')\n",
        "pl\n",
        "\n",
        "Se0=pl.iloc[:,0]\n",
        "Se1=pl.iloc[:,1]\n",
        "Se2=pl.iloc[:,2]\n"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5efICtcn4eK"
      },
      "source": [
        "pl = pd.read_csv('SerumGluPredictions.csv')\n",
        "pl\n",
        "\n",
        "Se0=pl.iloc[:,0]\n",
        "Se1=pl.iloc[:,1]\n",
        "Se2=pl.iloc[:,2]\n",
        "####Gender ---take the same output as existing"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqyGr7CiyTzf"
      },
      "source": [
        "\n",
        "Gen0=B0\n",
        "Gen1=B1\n",
        "Gen2=B2\n",
        "####Gender ---take the same output as existing"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5-aSPt-4nyl"
      },
      "source": [
        "G0,G1,G2 for Glucose\n",
        "A0,A1,A2 for Age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYiOQdz44vwx"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Ufejzy6AqL",
        "outputId": "b125da8c-d635-4a26-bc19-6ced61fa358d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "sum0=[]\n",
        "sum1=[]\n",
        "sum2=[]\n",
        "res=[]\n",
        "for (a0,a1,a2,b0,b1,b2,c0,c1,c2,d0,d1,d2,e0,e1,e2,f0,f1,f2,g0,g1,g2,h0,h1,h2,i0,i1,i2,j0,j1,j2,k0,k1,k2,l0,l1,l2) in zip(Gen0,Gen1,Gen2,A0,A1,A2,B0,B1,B2,W0,W1,W2,S0,S1,S2,D0,D1,D2,alb0,alb1,alb2,C0,C1,C2,G0,G1,G2,T0,T1,T2,a1c0,a1c1,a1c2,Se0,Se1,Se2):\n",
        "\n",
        "  s0= (a0*weight[0])+(b0*weight[1])+(c0*weight[2])+(d0*weight[3])+(e0*weight[4])+(f0*weight[5])+(g0*weight[6])+(h0*weight[7])+(i0*weight[8])+(j0*weight[9])+(k0*weight[10])+(l0*weight[11])\n",
        "  s1= (a1*weight[0])+(b1*weight[1])+(c1*weight[2])+(d1*weight[3])+(e1*weight[4])+(f1*weight[5])+(g1*weight[6])+(h1*weight[7])+(i1*weight[8])+(j1*weight[9])+(k1*weight[10])+(l1*weight[11])\n",
        "  s2= (a2*weight[0])+(b2*weight[1])+(c2*weight[2])+(d2*weight[3])+(e2*weight[4])+(f2*weight[5])+(g2*weight[6])+(h2*weight[7])+(i2*weight[8])+(j2*weight[9])+(k2*weight[10])+(l2*weight[11])\n",
        "\n",
        "  result =max(s0,s1,s2)\n",
        "  if result ==s0:\n",
        "    add=0\n",
        "  elif result ==s1:\n",
        "    add=1\n",
        "  elif result==s2:\n",
        "    add=2\n",
        "\n",
        "  res.append(add)\n",
        "\n",
        "print('result',res)\n"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 2, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 2, 0, 2, 1, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 1, 1, 2, 2, 0, 0, 2, 2, 2, 0, 1, 1, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 2, 1, 2, 0, 0, 0, 2, 0, 2, 2, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 0, 0, 1, 2, 1, 0, 0, 0, 2, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 2, 1, 0, 2, 2, 1, 2, 1, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 2, 0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 2, 1, 2, 2, 1, 0, 2, 2, 1, 2, 2, 2, 2, 0, 1, 1, 2, 2, 2, 0, 2, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 1, 1, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 1, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 2, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0, 1, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 1, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2, 1, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 1, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 1, 1, 0, 0, 2, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 1, 2, 2, 0, 2, 0, 0, 0, 1, 0, 2, 2, 0, 0, 1, 2, 2, 0, 0, 0, 0, 2, 0, 2, 1, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 0, 0, 2, 2, 1, 1, 2, 1, 1, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 2, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 2, 1, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 1, 1, 0, 1, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 1, 2, 2, 2, 0, 0, 1, 2, 2, 0, 2, 1, 2, 0, 0, 0, 2, 1, 2, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 1, 2, 1, 1, 1, 2, 2, 0, 2, 2, 2, 1, 0, 0, 2, 2, 0, 1, 0, 2, 2, 2, 1, 2, 2, 0, 2, 0, 0, 2, 1, 2, 0, 2, 2, 1, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 2, 0, 2, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 1, 2, 2, 1, 0, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 1, 2, 0, 2, 1, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 1, 2, 2, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 0, 2, 1, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 2, 2, 2, 0, 1, 1, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 1, 1, 1, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 0, 1, 2, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 1, 1, 0, 1, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 2, 0, 2, 2, 0, 0, 0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 0, 0, 0, 2, 0, 2, 0, 1, 2, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 2, 2, 0, 2, 0, 0, 1, 0, 1, 0, 1, 1, 2, 2, 0, 2, 0, 2, 0, 1, 2, 1, 0, 2, 2, 0, 2, 0, 0, 1, 0, 0, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 0, 2, 1, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 0, 1, 2, 1, 0, 2, 1, 2, 2, 2, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 1, 0, 2, 0, 0, 2, 2, 2, 1, 1, 1, 2, 1, 0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 2, 0, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 1, 1, 1, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 2, 2, 0, 1, 2, 0, 0, 0, 1, 0, 2, 2, 0, 0, 2, 1, 1, 1, 1, 2, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 0, 0, 1, 2, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 2, 0, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 1, 2, 0, 2, 1, 2, 2, 2, 1, 1, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 1, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 0, 0, 2, 1, 0, 1, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 0, 0, 2, 1, 1, 2, 0, 2, 2, 2, 0, 2, 0, 1, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 0, 0, 0, 0, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 1, 1, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 1, 0, 1, 2, 1, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 0, 2, 0, 2, 0, 2, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2, 1, 0, 0, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 2, 1, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 0, 1, 2, 1, 2, 1, 1, 0, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 1, 0, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 0, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wBJEnZvJAKc"
      },
      "source": [
        "df = pd.DataFrame(res)  \n",
        "\n",
        "df.to_csv('result.csv',index=False, header=True)"
      ],
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doBnB7FRJ6y8",
        "outputId": "075031e2-236c-4d3d-b3a1-d24701d573e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "df1 = pd.read_csv('miceDataset.csv')\n",
        "df2 = pd.read_csv('result.csv')\n",
        "\n",
        "\n",
        "Merged = pd.concat([df1, df2], axis = 1)\n",
        "Merged"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>dia_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>glucose</th>\n",
              "      <th>trigs</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>Diabetes</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>50.00000</td>\n",
              "      <td>11.77</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.700000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>60.00000</td>\n",
              "      <td>2.37</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.300000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>72.00000</td>\n",
              "      <td>3.73</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>94.160745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.100000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>3.74</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.600000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>64.00000</td>\n",
              "      <td>3.13</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.200000</td>\n",
              "      <td>140.666578</td>\n",
              "      <td>76.05274</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>207.939424</td>\n",
              "      <td>91.927995</td>\n",
              "      <td>205.687652</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>39.2</td>\n",
              "      <td>128.090281</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>33.20</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>6.3</td>\n",
              "      <td>106.720790</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>1.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.500000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>74.00000</td>\n",
              "      <td>3.92</td>\n",
              "      <td>181.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>1.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.700000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>78.00000</td>\n",
              "      <td>4.16</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>5.7</td>\n",
              "      <td>96.866305</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5206</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5207 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender   age   bmi    waist_cm  ...  a1c   glucose.1  Diabetes   result\n",
              "0        1.0  21.0  18.2   82.000000  ...  5.0   88.000000        0.0       0\n",
              "1        0.0  21.0  25.9   93.700000  ...  5.2   88.000000        0.0       0\n",
              "2        0.0  21.0  29.5  102.300000  ...  5.1   94.160745        0.0       0\n",
              "3        0.0  21.0  17.9   69.100000  ...  5.1   95.000000        0.0       0\n",
              "4        0.0  21.0  30.6  101.600000  ...  6.0   95.000000        0.0       0\n",
              "...      ...   ...   ...         ...  ...  ...         ...        ...     ...\n",
              "5202     0.0  77.0  32.9  122.200000  ...  6.2   98.000000        0.0       2\n",
              "5203     0.0  77.0  39.2  128.090281  ...  6.3  106.720790        1.0       2\n",
              "5204     1.0  77.0  36.5  119.500000  ...  6.2  103.000000        0.0       2\n",
              "5205     1.0  77.0  34.8  104.700000  ...  5.7   96.866305        1.0       2\n",
              "5206     NaN   NaN   NaN         NaN  ...  NaN         NaN        NaN       2\n",
              "\n",
              "[5207 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCgDvDVULA7a"
      },
      "source": [
        "Merged.to_csv('finalDiabetes.csv')\n",
        "\n"
      ],
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yFJewoB12H-"
      },
      "source": [
        "newy=[]\n",
        "newy=ynew"
      ],
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5UyGTh33V0T"
      },
      "source": [
        "ones=[]\n",
        "zeros=[]\n",
        "rem=[]"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "big0QOXo4cBb",
        "outputId": "927d19dc-cafc-4f80-9b1e-b38cdd7cb4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(newy)"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTBMiqyD4whE"
      },
      "source": [
        "len(res)\n",
        "rem=[]"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6KkSya_5y23",
        "outputId": "7036063e-ef34-4c6e-aeb4-9b60c2a55a79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(newy)\n",
        "print(res)"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1]\n",
            "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 2, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 2, 0, 2, 1, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 1, 1, 2, 2, 0, 0, 2, 2, 2, 0, 1, 1, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 2, 1, 2, 0, 0, 0, 2, 0, 2, 2, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 0, 0, 1, 2, 1, 0, 0, 0, 2, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 2, 1, 0, 2, 2, 1, 2, 1, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 2, 0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 2, 1, 2, 2, 1, 0, 2, 2, 1, 2, 2, 2, 2, 0, 1, 1, 2, 2, 2, 0, 2, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 1, 1, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 1, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 2, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0, 1, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 1, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2, 1, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 1, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 1, 1, 0, 0, 2, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 1, 2, 2, 0, 2, 0, 0, 0, 1, 0, 2, 2, 0, 0, 1, 2, 2, 0, 0, 0, 0, 2, 0, 2, 1, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 0, 0, 2, 2, 1, 1, 2, 1, 1, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 2, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 2, 1, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 1, 1, 0, 1, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 1, 2, 2, 2, 0, 0, 1, 2, 2, 0, 2, 1, 2, 0, 0, 0, 2, 1, 2, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 1, 2, 1, 1, 1, 2, 2, 0, 2, 2, 2, 1, 0, 0, 2, 2, 0, 1, 0, 2, 2, 2, 1, 2, 2, 0, 2, 0, 0, 2, 1, 2, 0, 2, 2, 1, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 2, 0, 2, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 1, 2, 2, 1, 0, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 1, 2, 0, 2, 1, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 1, 2, 2, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 0, 2, 1, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 2, 2, 2, 0, 1, 1, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 1, 1, 1, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 0, 1, 2, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 1, 1, 0, 1, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 2, 0, 2, 2, 0, 0, 0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 0, 0, 0, 2, 0, 2, 0, 1, 2, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 2, 2, 0, 2, 0, 0, 1, 0, 1, 0, 1, 1, 2, 2, 0, 2, 0, 2, 0, 1, 2, 1, 0, 2, 2, 0, 2, 0, 0, 1, 0, 0, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 0, 2, 1, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 0, 1, 2, 1, 0, 2, 1, 2, 2, 2, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 1, 0, 2, 0, 0, 2, 2, 2, 1, 1, 1, 2, 1, 0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 2, 0, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 1, 1, 1, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 2, 2, 0, 1, 2, 0, 0, 0, 1, 0, 2, 2, 0, 0, 2, 1, 1, 1, 1, 2, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 0, 0, 1, 2, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 2, 0, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 1, 2, 0, 2, 1, 2, 2, 2, 1, 1, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 1, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 0, 0, 2, 1, 0, 1, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 0, 0, 2, 1, 1, 2, 0, 2, 2, 2, 0, 2, 0, 1, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 0, 0, 0, 0, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 1, 1, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 1, 0, 1, 2, 1, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 0, 2, 0, 2, 0, 2, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2, 1, 0, 0, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 2, 1, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 0, 1, 2, 1, 2, 1, 1, 0, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 1, 0, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 0, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUp9I-Ts2Obd",
        "outputId": "4f6b377a-78b7-45c3-ec56-ce8726cd0f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "for i,j in zip(newy,res):\n",
        "  if i==j:\n",
        "    if i==1:\n",
        "          add=1\n",
        "          ones.append(add)\n",
        "    elif i==0:\n",
        "                add=0\n",
        "                zeros.append(add)\n",
        "  else:\n",
        "    add=2\n",
        "    rem.append(add)\n",
        "\n",
        "print(len(ones))\n",
        "print(len(zeros))\n",
        "len(rem)\n"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "567\n",
            "3134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1505"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIz4FhFV7KZ_"
      },
      "source": [
        "data = pd.read_csv(r'miceDataset.csv')"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4my9RrD7Ogn",
        "outputId": "c6a681cf-01d9-4660-d131-4cff0a4e83f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = data.iloc[:, 0:12].values\n",
        "y = data.iloc[:, 12].values\n",
        "x\n",
        "y"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcqf4VKX7SfM",
        "outputId": "f2ef672c-72ea-415a-b494-641ce74704a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "res"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pXHH3iE8ZZ0"
      },
      "source": [
        "acc=0"
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5khsx4W162xa",
        "outputId": "baf13ad4-d499-465f-f82f-b04dd72eb860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "while acc<0.99:\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, res, test_size=0.2)\n",
        "# Preprocessing\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train)\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "  RFclassifier = RandomForestClassifier(n_estimators = 100,random_state=0,warm_start=True)\n",
        "  RFclassifier.fit(x_train, y_train)\n",
        "  y_pred = RFclassifier.predict(x_test)\n",
        "  #print(confusion_matrix(y_test, y_pred))\n",
        "  acc=accuracy_score(y_test,y_pred)\n",
        "  print(acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9865642994241842\n",
            "0.9750479846449136\n",
            "0.9875239923224568\n",
            "0.9932821497120922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJsGBP8v-tie"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlhWhiiWBzdw",
        "outputId": "a041ed0b-0bb0-4452-c78c-509d44ff2bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 2, 0, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flST5s9D-BUB",
        "outputId": "f19a1bbe-ad77-40c7-84d7-e49224b11043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "print('Classifier Type: Random Forest')\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test, y_pred))\n",
        "acc=accuracy_score(y_test,y_pred)\n",
        "print('Accuracy: ',acc)"
      ],
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier Type: Random Forest\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       633\n",
            "           1       0.99      0.99      0.99       119\n",
            "           2       0.99      0.98      0.99       290\n",
            "\n",
            "    accuracy                           0.99      1042\n",
            "   macro avg       0.99      0.99      0.99      1042\n",
            "weighted avg       0.99      0.99      0.99      1042\n",
            "\n",
            "Accuracy:  0.9932821497120922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujteOJW7DAEu",
        "outputId": "7b7d3c8d-c402-4933-813c-978ff012adc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('ROC_AUC_SCORE: ',multiclass_roc_auc_score(y_test,y_pred,average='macro'))\n"
      ],
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC_AUC_SCORE:  0.9932087552211982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADpkt0c2CtHd"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred)\n",
        "  return roc_auc_score(y_test, y_pred, average=average)"
      ],
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuAn5WfMDUWo"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ_ybKmOFdD0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EAcZlV-8T9N"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, res, test_size=0.2)\n"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv-wuwT28w6N"
      },
      "source": [
        "\n",
        "import pickle\n",
        "filename = 'thresholded993RF.pkl'\n",
        "pickle.dump(RFclassifier, open(filename, 'wb'))"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV9SDeXYFsxm"
      },
      "source": [
        "acc=0"
      ],
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAGCJfWwFfP0",
        "outputId": "00f30f8f-d337-4972-c3be-e0c24a83e8e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "while acc<0.98:\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, res, test_size=0.2)\n",
        "# Preprocessing\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train)\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "  LRclassifier = LogisticRegression()\n",
        "  LRclassifier.fit(x_train, y_train)\n",
        "  y_pred = LRclassifier.predict(x_test)\n",
        "  acc=accuracy_score(y_test,y_pred)\n",
        "  print(acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9673704414587332\n",
            "0.9664107485604606\n",
            "0.9664107485604606\n",
            "0.9683301343570058\n",
            "0.9817658349328215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6IiOcXIGC5K",
        "outputId": "2d696b1a-a699-4e60-d2a2-758599775ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "print('Classifier Type: Logistic Regression')\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test, y_pred))\n",
        "acc=accuracy_score(y_test,y_pred)\n",
        "print('Accuracy: ',acc)\n",
        "print('ROC_AUC_SCORE: ',multiclass_roc_auc_score(y_test,y_pred,average='macro'))\n"
      ],
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier Type: Logistic Regression\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       637\n",
            "           1       1.00      0.99      1.00       138\n",
            "           2       0.97      0.96      0.96       267\n",
            "\n",
            "    accuracy                           0.98      1042\n",
            "   macro avg       0.98      0.98      0.98      1042\n",
            "weighted avg       0.98      0.98      0.98      1042\n",
            "\n",
            "Accuracy:  0.9817658349328215\n",
            "ROC_AUC_SCORE:  0.9838471726424024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l_fmYeHGuy1"
      },
      "source": [
        "\n",
        "# Polynomial Kernel\n",
        "from sklearn.svm import SVC   # Support Vector Classifier\n"
      ],
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QahHrf93HfjH"
      },
      "source": [
        "acc=0"
      ],
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc4954zGGkkT",
        "outputId": "876d79de-bca2-48d6-badb-911ea508ede9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        }
      },
      "source": [
        "while acc<0.98:\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, res, test_size=0.2)\n",
        "# Preprocessing\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train)\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "  SVMclassifier = SVC(kernel='rbf')\n",
        "  SVMclassifier.fit(x_train, y_train) \n",
        "  y_pred = LRclassifier.predict(x_test)\n",
        "  acc=accuracy_score(y_test,y_pred)\n",
        "  print(acc)\n",
        "\n",
        "\n",
        "\n",
        "print('Classifier Type: SVM')\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test, y_pred))\n",
        "acc=accuracy_score(y_test,y_pred)\n",
        "print('Accuracy: ',acc)\n",
        "print('ROC_AUC_SCORE: ',multiclass_roc_auc_score(y_test,y_pred,average='macro'))\n"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9606525911708254\n",
            "0.9616122840690979\n",
            "0.9712092130518234\n",
            "0.9606525911708254\n",
            "0.9798464491362764\n",
            "0.9712092130518234\n",
            "0.963531669865643\n",
            "0.9712092130518234\n",
            "0.9692898272552783\n",
            "0.9769673704414588\n",
            "0.9712092130518234\n",
            "0.9712092130518234\n",
            "0.9664107485604606\n",
            "0.972168905950096\n",
            "0.974088291746641\n",
            "0.9712092130518234\n",
            "0.9702495201535508\n",
            "0.9664107485604606\n",
            "0.972168905950096\n",
            "0.9596928982725528\n",
            "0.972168905950096\n",
            "0.974088291746641\n",
            "0.9817658349328215\n",
            "Classifier Type: SVM\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       622\n",
            "           1       1.00      1.00      1.00       120\n",
            "           2       0.99      0.94      0.97       300\n",
            "\n",
            "    accuracy                           0.98      1042\n",
            "   macro avg       0.99      0.98      0.98      1042\n",
            "weighted avg       0.98      0.98      0.98      1042\n",
            "\n",
            "Accuracy:  0.9817658349328215\n",
            "ROC_AUC_SCORE:  0.9828243818306307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Chenm7khob"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6vzGNtydlBy"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, ynew, test_size=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POe4-7Hcd5MI"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBcr3-6UVmiL"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPWlfj2dd7_-"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0A6ktnad-jl"
      },
      "source": [
        "RFclassifier = RandomForestClassifier(n_estimators = 100,random_state=0,warm_start=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfgQl7t0eCnx",
        "outputId": "23d03a12-a1bd-471a-a12e-692a23eedf1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "RFclassifier.fit(x_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xwxXkESiDLF"
      },
      "source": [
        "y_pred = RFclassifier.predict(x_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF7EvAnviILD",
        "outputId": "da107ea6-4802-4af5-ea8d-ca355b65dfa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "  print(confusion_matrix(y_test, y_pred))\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  acc=accuracy_score(y_test, y_pred)\n",
        "  print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[890   1]\n",
            " [ 27 123]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       891\n",
            "           1       0.99      0.82      0.90       150\n",
            "\n",
            "    accuracy                           0.97      1041\n",
            "   macro avg       0.98      0.91      0.94      1041\n",
            "weighted avg       0.97      0.97      0.97      1041\n",
            "\n",
            "0.9731027857829011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osejj5pViMok"
      },
      "source": [
        "\n",
        "import pickle\n",
        "filename = 'rf1.pkl'\n",
        "pickle.dump(RFclassifier, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syh6A9qliuFR",
        "outputId": "1b3ac81b-ad5c-4ad7-d86b-d937eb6b1c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "pip install sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc9e8zqEixAE"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2rtuOTligJr",
        "outputId": "66e38b37-a185-443b-9702-e9e27b1939b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "roc_auc_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.909438832772166"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0vcrAq2jKY6"
      },
      "source": [
        "acc=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjwo9F7ai5e0"
      },
      "source": [
        "trial 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMgxlZBWi7je"
      },
      "source": [
        "while acc<0.98:\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, ynew, test_size=0.2)\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train)\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "\n",
        "  RFclassifier = RandomForestClassifier(n_estimators = 200,random_state=0,warm_start=True)\n",
        "  RFclassifier.fit(x_train, y_train)\n",
        "  y_pred = RFclassifier.predict(x_test)\n",
        "  #print(confusion_matrix(y_test, y_pred))\n",
        "  #print(classification_report(y_test, y_pred))\n",
        "  acc=accuracy_score(y_test, y_pred)\n",
        "  print(acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdTdSv64kwQ1",
        "outputId": "62d6099b-4432-4f35-f7b8-7d2c53288b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "  print('confusion matrix',confusion_matrix(y_test, y_pred))\n",
        "  print('Classification report',classification_report(y_test, y_pred))\n",
        "  acc=accuracy_score(y_test, y_pred)\n",
        "  print('accuracy',acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix [[903   2]\n",
            " [ 17 119]]\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       905\n",
            "           1       0.98      0.88      0.93       136\n",
            "\n",
            "    accuracy                           0.98      1041\n",
            "   macro avg       0.98      0.94      0.96      1041\n",
            "weighted avg       0.98      0.98      0.98      1041\n",
            "\n",
            "accuracy 0.9817483189241114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC4A003QksF4",
        "outputId": "605c2002-220a-4137-cdf8-66b35113276a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('AUC score',roc_auc_score(y_test,y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score 0.9363950276243094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCmSZY5mkVlW"
      },
      "source": [
        "\n",
        "import pickle\n",
        "filename = 'rf2.pkl'\n",
        "pickle.dump(RFclassifier, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoKLVBuCVroy"
      },
      "source": [
        "import pandas as pd\n",
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from fancyimpute import IterativeImputer\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD-9WOmAWGRO"
      },
      "source": [
        "# LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ewUQGXVxO8"
      },
      "source": [
        "lgb_clf = lgb.LGBMClassifier(random_state=0, silent=True, metric='None', n_jobs=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HerliRemV3Eq",
        "outputId": "a14dfa6e-8eb7-44ea-ec93-544905652af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "lgb_clf.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "               metric='None', min_child_samples=20, min_child_weight=0.001,\n",
              "               min_split_gain=0.0, n_estimators=100, n_jobs=4, num_leaves=31,\n",
              "               objective=None, random_state=0, reg_alpha=0.0, reg_lambda=0.0,\n",
              "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
              "               subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alJ3FJ3aV55I"
      },
      "source": [
        "y_pred = lgb_clf.predict(x_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ3TWRoul0Dt"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFp5l8UOlk0T"
      },
      "source": [
        "pickle.dump(lgb_clf, open('lgbClassifier.pkl', 'wb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoG_ypbxXdeC",
        "outputId": "5ceb0341-e716-4e27-a522-ceae2e937960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       886\n",
            "           1       0.97      0.81      0.88       155\n",
            "\n",
            "    accuracy                           0.97      1041\n",
            "   macro avg       0.97      0.90      0.93      1041\n",
            "weighted avg       0.97      0.97      0.97      1041\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwmQweampKTg"
      },
      "source": [
        "# BORUTA SELECTOR + RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiDfvaKEn2o8",
        "outputId": "dd382d62-8364-40d1-d00c-3e2672feae3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "pip install boruta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting boruta\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/11/583f4eac99d802c79af9217e1eff56027742a69e6c866b295cce6a5a8fc2/Boruta-0.3-py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from boruta) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from boruta) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from boruta) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17.1->boruta) (0.16.0)\n",
            "Installing collected packages: boruta\n",
            "Successfully installed boruta-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKVVxGU-Xe_W"
      },
      "source": [
        "from boruta import BorutaPy\n",
        "from datetime import datetime\n",
        "from __future__ import print_function\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS8GjTG0snJ8"
      },
      "source": [
        "def timer(start_time=None):\n",
        "    if not start_time:\n",
        "        start_time = datetime.now()\n",
        "        return start_time\n",
        "    elif start_time:\n",
        "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
        "        tmin, tsec = divmod(temp_sec, 60)\n",
        "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4xKVY4YssNm"
      },
      "source": [
        "rfc = RandomForestClassifier(n_estimators=200, class_weight='balanced')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "327MbkQntJKN",
        "outputId": "98911558-a83f-4609-8d13-67b34bbfea3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2)\n",
        "start_time = timer(None)\n",
        "boruta_selector.fit(x_train, y_train)\n",
        "timer(start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t9\n",
            "Rejected: \t29\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t9\n",
            "Rejected: \t29\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t9\n",
            "Rejected: \t29\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t6\n",
            "Rejected: \t32\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t6\n",
            "Rejected: \t32\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t6\n",
            "Rejected: \t32\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t0\n",
            "Rejected: \t36\n",
            "\n",
            " Time taken: 0 hours 1 minutes and 28.77 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1orVYVvt4j-",
        "outputId": "bd3c5cc6-a407-4ed7-d813-956329c09a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>race</th>\n",
              "      <th>education</th>\n",
              "      <th>marital</th>\n",
              "      <th>income</th>\n",
              "      <th>household_size</th>\n",
              "      <th>insurance</th>\n",
              "      <th>private_insur</th>\n",
              "      <th>gen_health</th>\n",
              "      <th>asthma</th>\n",
              "      <th>chf</th>\n",
              "      <th>cad</th>\n",
              "      <th>mi</th>\n",
              "      <th>cva</th>\n",
              "      <th>copd</th>\n",
              "      <th>cancer</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>depression</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>smoker</th>\n",
              "      <th>drinks_day</th>\n",
              "      <th>weight_kg</th>\n",
              "      <th>height_cm</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>dia_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>alb</th>\n",
              "      <th>alt</th>\n",
              "      <th>ast</th>\n",
              "      <th>alk_phos</th>\n",
              "      <th>bun</th>\n",
              "      <th>ca</th>\n",
              "      <th>cpk</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>bicarb</th>\n",
              "      <th>cr</th>\n",
              "      <th>glucose</th>\n",
              "      <th>iron</th>\n",
              "      <th>ldh</th>\n",
              "      <th>phos</th>\n",
              "      <th>t_bilirubin</th>\n",
              "      <th>t_protein</th>\n",
              "      <th>u_acid</th>\n",
              "      <th>sodium</th>\n",
              "      <th>potassium</th>\n",
              "      <th>chloride</th>\n",
              "      <th>glob</th>\n",
              "      <th>trigs</th>\n",
              "      <th>wbc</th>\n",
              "      <th>hgb</th>\n",
              "      <th>hct</th>\n",
              "      <th>platelets</th>\n",
              "      <th>s_cotinine</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>insulin</th>\n",
              "      <th>hdl</th>\n",
              "      <th>ldl_chol</th>\n",
              "      <th>grip_strength</th>\n",
              "      <th>fvc</th>\n",
              "      <th>fev1</th>\n",
              "      <th>fev1_fvc_ratio</th>\n",
              "      <th>Diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>50.8</td>\n",
              "      <td>167.1</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>11.77</td>\n",
              "      <td>4.4</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.8</td>\n",
              "      <td>35.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.44</td>\n",
              "      <td>82.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>138.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>105.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>54.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.7</td>\n",
              "      <td>36.1</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.654</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>7.27</td>\n",
              "      <td>47.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>50.3</td>\n",
              "      <td>3650.0</td>\n",
              "      <td>2846.0</td>\n",
              "      <td>0.779726</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>72.8</td>\n",
              "      <td>167.5</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.7</td>\n",
              "      <td>110.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>2.37</td>\n",
              "      <td>4.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.6</td>\n",
              "      <td>214.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.81</td>\n",
              "      <td>81.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.2</td>\n",
              "      <td>7.3</td>\n",
              "      <td>7.8</td>\n",
              "      <td>137.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>102.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>83.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>15.1</td>\n",
              "      <td>44.4</td>\n",
              "      <td>226.0</td>\n",
              "      <td>0.221</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88.0</td>\n",
              "      <td>12.01</td>\n",
              "      <td>40.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>90.1</td>\n",
              "      <td>4327.0</td>\n",
              "      <td>3629.0</td>\n",
              "      <td>0.838687</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>165.6</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.3</td>\n",
              "      <td>114.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>4.5</td>\n",
              "      <td>23.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.3</td>\n",
              "      <td>73.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.82</td>\n",
              "      <td>87.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>7.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>104.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>8.2</td>\n",
              "      <td>14.4</td>\n",
              "      <td>41.3</td>\n",
              "      <td>266.0</td>\n",
              "      <td>0.011</td>\n",
              "      <td>5.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.7</td>\n",
              "      <td>4471.0</td>\n",
              "      <td>3725.0</td>\n",
              "      <td>0.833147</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>56.9</td>\n",
              "      <td>178.3</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.1</td>\n",
              "      <td>108.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>3.74</td>\n",
              "      <td>4.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>151.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.73</td>\n",
              "      <td>91.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>7.4</td>\n",
              "      <td>5.9</td>\n",
              "      <td>136.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>102.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>57.0</td>\n",
              "      <td>6.6</td>\n",
              "      <td>14.7</td>\n",
              "      <td>43.0</td>\n",
              "      <td>206.0</td>\n",
              "      <td>16.300</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95.0</td>\n",
              "      <td>3.60</td>\n",
              "      <td>55.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>86.6</td>\n",
              "      <td>5161.0</td>\n",
              "      <td>4301.0</td>\n",
              "      <td>0.833366</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>101.2</td>\n",
              "      <td>181.9</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.6</td>\n",
              "      <td>134.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>4.3</td>\n",
              "      <td>20.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>250.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.07</td>\n",
              "      <td>89.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>0.8</td>\n",
              "      <td>7.2</td>\n",
              "      <td>7.2</td>\n",
              "      <td>142.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>104.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>70.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>15.6</td>\n",
              "      <td>45.1</td>\n",
              "      <td>306.0</td>\n",
              "      <td>212.000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>14.58</td>\n",
              "      <td>39.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>94.4</td>\n",
              "      <td>6250.0</td>\n",
              "      <td>5168.0</td>\n",
              "      <td>0.826880</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>7</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.6</td>\n",
              "      <td>161.5</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.9</td>\n",
              "      <td>130.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>11.43</td>\n",
              "      <td>4.2</td>\n",
              "      <td>26.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>198.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.73</td>\n",
              "      <td>126.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>6.9</td>\n",
              "      <td>7.6</td>\n",
              "      <td>138.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>107.0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>130.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>14.2</td>\n",
              "      <td>41.8</td>\n",
              "      <td>205.0</td>\n",
              "      <td>0.269</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134.0</td>\n",
              "      <td>19.13</td>\n",
              "      <td>45.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>65.2</td>\n",
              "      <td>3097.0</td>\n",
              "      <td>2249.0</td>\n",
              "      <td>0.726187</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>104.6</td>\n",
              "      <td>178.3</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>10.4</td>\n",
              "      <td>29.6</td>\n",
              "      <td>141.0</td>\n",
              "      <td>143.000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2872.0</td>\n",
              "      <td>1716.0</td>\n",
              "      <td>0.597493</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>39.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>33.20</td>\n",
              "      <td>3.6</td>\n",
              "      <td>32.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>94.0</td>\n",
              "      <td>197.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.98</td>\n",
              "      <td>101.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>7.5</td>\n",
              "      <td>7.2</td>\n",
              "      <td>138.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>104.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>169.0</td>\n",
              "      <td>10.7</td>\n",
              "      <td>14.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.011</td>\n",
              "      <td>6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.8</td>\n",
              "      <td>168.6</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.5</td>\n",
              "      <td>128.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>3.92</td>\n",
              "      <td>4.1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10.3</td>\n",
              "      <td>236.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.95</td>\n",
              "      <td>103.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>137.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>103.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>67.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>13.5</td>\n",
              "      <td>38.7</td>\n",
              "      <td>213.0</td>\n",
              "      <td>0.035</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103.0</td>\n",
              "      <td>11.77</td>\n",
              "      <td>69.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>45.2</td>\n",
              "      <td>2060.0</td>\n",
              "      <td>1491.0</td>\n",
              "      <td>0.723786</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.1</td>\n",
              "      <td>153.6</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.7</td>\n",
              "      <td>150.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>4.16</td>\n",
              "      <td>3.7</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.72</td>\n",
              "      <td>93.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>6.2</td>\n",
              "      <td>4.4</td>\n",
              "      <td>142.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>117.0</td>\n",
              "      <td>5.3</td>\n",
              "      <td>11.3</td>\n",
              "      <td>35.2</td>\n",
              "      <td>334.0</td>\n",
              "      <td>0.237</td>\n",
              "      <td>5.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.4</td>\n",
              "      <td>1207.0</td>\n",
              "      <td>734.0</td>\n",
              "      <td>0.608119</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 66 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  age  race  education  ...     fvc    fev1  fev1_fvc_ratio  Diabetes \n",
              "0          1   21     7        2.0  ...  3650.0  2846.0        0.779726        0.0\n",
              "1          0   21     1        2.0  ...  4327.0  3629.0        0.838687        0.0\n",
              "2          0   21     2        3.0  ...  4471.0  3725.0        0.833147        0.0\n",
              "3          0   21     1        2.0  ...  5161.0  4301.0        0.833366        0.0\n",
              "4          0   21     2        3.0  ...  6250.0  5168.0        0.826880        0.0\n",
              "...      ...  ...   ...        ...  ...     ...     ...             ...        ...\n",
              "5201       0   77     7        5.0  ...  3097.0  2249.0        0.726187        1.0\n",
              "5202       0   77     4        3.0  ...  2872.0  1716.0        0.597493        0.0\n",
              "5203       0   77     3        4.0  ...     0.0     0.0        0.000000        1.0\n",
              "5204       1   77     4        2.0  ...  2060.0  1491.0        0.723786        0.0\n",
              "5205       1   77     4        3.0  ...  1207.0   734.0        0.608119        1.0\n",
              "\n",
              "[5206 rows x 66 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J78MLWdgt78V",
        "outputId": "a4cdf9fb-7d73-47de-8b69-4c29aef60f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "data = pd.read_csv(r'filled_Noheader.csv')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>race</th>\n",
              "      <th>education</th>\n",
              "      <th>marital</th>\n",
              "      <th>income</th>\n",
              "      <th>household_size</th>\n",
              "      <th>insurance</th>\n",
              "      <th>private_insur</th>\n",
              "      <th>gen_health</th>\n",
              "      <th>asthma</th>\n",
              "      <th>chf</th>\n",
              "      <th>cad</th>\n",
              "      <th>mi</th>\n",
              "      <th>cva</th>\n",
              "      <th>copd</th>\n",
              "      <th>cancer</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>depression</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>smoker</th>\n",
              "      <th>drinks_day</th>\n",
              "      <th>weight_kg</th>\n",
              "      <th>height_cm</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>dia_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>alb</th>\n",
              "      <th>alt</th>\n",
              "      <th>ast</th>\n",
              "      <th>alk_phos</th>\n",
              "      <th>bun</th>\n",
              "      <th>ca</th>\n",
              "      <th>cpk</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>bicarb</th>\n",
              "      <th>cr</th>\n",
              "      <th>glucose</th>\n",
              "      <th>iron</th>\n",
              "      <th>ldh</th>\n",
              "      <th>phos</th>\n",
              "      <th>t_bilirubin</th>\n",
              "      <th>t_protein</th>\n",
              "      <th>u_acid</th>\n",
              "      <th>sodium</th>\n",
              "      <th>potassium</th>\n",
              "      <th>chloride</th>\n",
              "      <th>glob</th>\n",
              "      <th>trigs</th>\n",
              "      <th>wbc</th>\n",
              "      <th>hgb</th>\n",
              "      <th>hct</th>\n",
              "      <th>platelets</th>\n",
              "      <th>s_cotinine</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>insulin</th>\n",
              "      <th>hdl</th>\n",
              "      <th>ldl_chol</th>\n",
              "      <th>grip_strength</th>\n",
              "      <th>fvc</th>\n",
              "      <th>fev1</th>\n",
              "      <th>fev1_fvc_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>50.8</td>\n",
              "      <td>167.1</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.0</td>\n",
              "      <td>96</td>\n",
              "      <td>50</td>\n",
              "      <td>11.77</td>\n",
              "      <td>4.4</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>44</td>\n",
              "      <td>7</td>\n",
              "      <td>8.8</td>\n",
              "      <td>35</td>\n",
              "      <td>118</td>\n",
              "      <td>25</td>\n",
              "      <td>0.44</td>\n",
              "      <td>82</td>\n",
              "      <td>165</td>\n",
              "      <td>75</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>138</td>\n",
              "      <td>3.4</td>\n",
              "      <td>105</td>\n",
              "      <td>2.9</td>\n",
              "      <td>54</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.7</td>\n",
              "      <td>36.1</td>\n",
              "      <td>157</td>\n",
              "      <td>0.654</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88</td>\n",
              "      <td>7.27</td>\n",
              "      <td>47</td>\n",
              "      <td>49</td>\n",
              "      <td>50.3</td>\n",
              "      <td>3650</td>\n",
              "      <td>2846</td>\n",
              "      <td>0.779726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>72.8</td>\n",
              "      <td>167.5</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.7</td>\n",
              "      <td>110</td>\n",
              "      <td>60</td>\n",
              "      <td>2.37</td>\n",
              "      <td>4.5</td>\n",
              "      <td>25</td>\n",
              "      <td>24</td>\n",
              "      <td>112</td>\n",
              "      <td>13</td>\n",
              "      <td>9.6</td>\n",
              "      <td>214</td>\n",
              "      <td>172</td>\n",
              "      <td>27</td>\n",
              "      <td>0.81</td>\n",
              "      <td>81</td>\n",
              "      <td>119</td>\n",
              "      <td>137</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.2</td>\n",
              "      <td>7.3</td>\n",
              "      <td>7.8</td>\n",
              "      <td>137</td>\n",
              "      <td>3.5</td>\n",
              "      <td>102</td>\n",
              "      <td>2.8</td>\n",
              "      <td>83</td>\n",
              "      <td>6.9</td>\n",
              "      <td>15.1</td>\n",
              "      <td>44.4</td>\n",
              "      <td>226</td>\n",
              "      <td>0.221</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88</td>\n",
              "      <td>12.01</td>\n",
              "      <td>40</td>\n",
              "      <td>112</td>\n",
              "      <td>90.1</td>\n",
              "      <td>4327</td>\n",
              "      <td>3629</td>\n",
              "      <td>0.838687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>81.0</td>\n",
              "      <td>165.6</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.3</td>\n",
              "      <td>114</td>\n",
              "      <td>72</td>\n",
              "      <td>3.73</td>\n",
              "      <td>4.5</td>\n",
              "      <td>23</td>\n",
              "      <td>21</td>\n",
              "      <td>103</td>\n",
              "      <td>10</td>\n",
              "      <td>9.3</td>\n",
              "      <td>73</td>\n",
              "      <td>168</td>\n",
              "      <td>25</td>\n",
              "      <td>0.82</td>\n",
              "      <td>87</td>\n",
              "      <td>68</td>\n",
              "      <td>112</td>\n",
              "      <td>4.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>7.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>138</td>\n",
              "      <td>3.5</td>\n",
              "      <td>104</td>\n",
              "      <td>3.0</td>\n",
              "      <td>256</td>\n",
              "      <td>8.2</td>\n",
              "      <td>14.4</td>\n",
              "      <td>41.3</td>\n",
              "      <td>266</td>\n",
              "      <td>0.011</td>\n",
              "      <td>5.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>72.7</td>\n",
              "      <td>4471</td>\n",
              "      <td>3725</td>\n",
              "      <td>0.833147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>56.9</td>\n",
              "      <td>178.3</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.1</td>\n",
              "      <td>108</td>\n",
              "      <td>62</td>\n",
              "      <td>3.74</td>\n",
              "      <td>4.8</td>\n",
              "      <td>18</td>\n",
              "      <td>23</td>\n",
              "      <td>65</td>\n",
              "      <td>10</td>\n",
              "      <td>9.5</td>\n",
              "      <td>151</td>\n",
              "      <td>144</td>\n",
              "      <td>26</td>\n",
              "      <td>0.73</td>\n",
              "      <td>91</td>\n",
              "      <td>63</td>\n",
              "      <td>87</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>7.4</td>\n",
              "      <td>5.9</td>\n",
              "      <td>136</td>\n",
              "      <td>3.6</td>\n",
              "      <td>102</td>\n",
              "      <td>2.6</td>\n",
              "      <td>57</td>\n",
              "      <td>6.6</td>\n",
              "      <td>14.7</td>\n",
              "      <td>43.0</td>\n",
              "      <td>206</td>\n",
              "      <td>16.300</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95</td>\n",
              "      <td>3.60</td>\n",
              "      <td>55</td>\n",
              "      <td>73</td>\n",
              "      <td>86.6</td>\n",
              "      <td>5161</td>\n",
              "      <td>4301</td>\n",
              "      <td>0.833366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>101.2</td>\n",
              "      <td>181.9</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.6</td>\n",
              "      <td>134</td>\n",
              "      <td>64</td>\n",
              "      <td>3.13</td>\n",
              "      <td>4.3</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>55</td>\n",
              "      <td>9</td>\n",
              "      <td>9.4</td>\n",
              "      <td>250</td>\n",
              "      <td>104</td>\n",
              "      <td>28</td>\n",
              "      <td>1.07</td>\n",
              "      <td>89</td>\n",
              "      <td>121</td>\n",
              "      <td>104</td>\n",
              "      <td>4.3</td>\n",
              "      <td>0.8</td>\n",
              "      <td>7.2</td>\n",
              "      <td>7.2</td>\n",
              "      <td>142</td>\n",
              "      <td>4.7</td>\n",
              "      <td>104</td>\n",
              "      <td>2.9</td>\n",
              "      <td>70</td>\n",
              "      <td>7.8</td>\n",
              "      <td>15.6</td>\n",
              "      <td>45.1</td>\n",
              "      <td>306</td>\n",
              "      <td>212.000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95</td>\n",
              "      <td>14.58</td>\n",
              "      <td>39</td>\n",
              "      <td>55</td>\n",
              "      <td>94.4</td>\n",
              "      <td>6250</td>\n",
              "      <td>5168</td>\n",
              "      <td>0.826880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>85.6</td>\n",
              "      <td>161.5</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.9</td>\n",
              "      <td>130</td>\n",
              "      <td>64</td>\n",
              "      <td>11.43</td>\n",
              "      <td>4.2</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>50</td>\n",
              "      <td>14</td>\n",
              "      <td>8.9</td>\n",
              "      <td>198</td>\n",
              "      <td>171</td>\n",
              "      <td>22</td>\n",
              "      <td>0.73</td>\n",
              "      <td>126</td>\n",
              "      <td>67</td>\n",
              "      <td>119</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>6.9</td>\n",
              "      <td>7.6</td>\n",
              "      <td>138</td>\n",
              "      <td>3.9</td>\n",
              "      <td>107</td>\n",
              "      <td>2.7</td>\n",
              "      <td>130</td>\n",
              "      <td>6.1</td>\n",
              "      <td>14.2</td>\n",
              "      <td>41.8</td>\n",
              "      <td>205</td>\n",
              "      <td>0.269</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134</td>\n",
              "      <td>19.13</td>\n",
              "      <td>45</td>\n",
              "      <td>92</td>\n",
              "      <td>65.2</td>\n",
              "      <td>3097</td>\n",
              "      <td>2249</td>\n",
              "      <td>0.726187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>104.6</td>\n",
              "      <td>178.3</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>10.4</td>\n",
              "      <td>29.6</td>\n",
              "      <td>141</td>\n",
              "      <td>143.000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2872</td>\n",
              "      <td>1716</td>\n",
              "      <td>0.597493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>39.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>136</td>\n",
              "      <td>62</td>\n",
              "      <td>33.20</td>\n",
              "      <td>3.6</td>\n",
              "      <td>32</td>\n",
              "      <td>28</td>\n",
              "      <td>61</td>\n",
              "      <td>18</td>\n",
              "      <td>8.9</td>\n",
              "      <td>94</td>\n",
              "      <td>197</td>\n",
              "      <td>24</td>\n",
              "      <td>0.98</td>\n",
              "      <td>101</td>\n",
              "      <td>123</td>\n",
              "      <td>161</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>7.5</td>\n",
              "      <td>7.2</td>\n",
              "      <td>138</td>\n",
              "      <td>3.7</td>\n",
              "      <td>104</td>\n",
              "      <td>3.9</td>\n",
              "      <td>169</td>\n",
              "      <td>10.7</td>\n",
              "      <td>14.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>195</td>\n",
              "      <td>0.011</td>\n",
              "      <td>6.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>103.8</td>\n",
              "      <td>168.6</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.5</td>\n",
              "      <td>128</td>\n",
              "      <td>74</td>\n",
              "      <td>3.92</td>\n",
              "      <td>4.1</td>\n",
              "      <td>14</td>\n",
              "      <td>22</td>\n",
              "      <td>80</td>\n",
              "      <td>14</td>\n",
              "      <td>10.3</td>\n",
              "      <td>236</td>\n",
              "      <td>181</td>\n",
              "      <td>23</td>\n",
              "      <td>0.95</td>\n",
              "      <td>103</td>\n",
              "      <td>69</td>\n",
              "      <td>138</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>137</td>\n",
              "      <td>3.9</td>\n",
              "      <td>103</td>\n",
              "      <td>3.3</td>\n",
              "      <td>67</td>\n",
              "      <td>4.3</td>\n",
              "      <td>13.5</td>\n",
              "      <td>38.7</td>\n",
              "      <td>213</td>\n",
              "      <td>0.035</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103</td>\n",
              "      <td>11.77</td>\n",
              "      <td>69</td>\n",
              "      <td>109</td>\n",
              "      <td>45.2</td>\n",
              "      <td>2060</td>\n",
              "      <td>1491</td>\n",
              "      <td>0.723786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>82.1</td>\n",
              "      <td>153.6</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.7</td>\n",
              "      <td>150</td>\n",
              "      <td>78</td>\n",
              "      <td>4.16</td>\n",
              "      <td>3.7</td>\n",
              "      <td>12</td>\n",
              "      <td>18</td>\n",
              "      <td>84</td>\n",
              "      <td>8</td>\n",
              "      <td>9.0</td>\n",
              "      <td>128</td>\n",
              "      <td>223</td>\n",
              "      <td>28</td>\n",
              "      <td>0.72</td>\n",
              "      <td>93</td>\n",
              "      <td>56</td>\n",
              "      <td>161</td>\n",
              "      <td>3.7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>6.2</td>\n",
              "      <td>4.4</td>\n",
              "      <td>142</td>\n",
              "      <td>4.0</td>\n",
              "      <td>104</td>\n",
              "      <td>2.5</td>\n",
              "      <td>117</td>\n",
              "      <td>5.3</td>\n",
              "      <td>11.3</td>\n",
              "      <td>35.2</td>\n",
              "      <td>334</td>\n",
              "      <td>0.237</td>\n",
              "      <td>5.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>57.4</td>\n",
              "      <td>1207</td>\n",
              "      <td>734</td>\n",
              "      <td>0.608119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 65 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  age  race  education  ...  grip_strength   fvc  fev1  fev1_fvc_ratio\n",
              "0          1   21     7          2  ...           50.3  3650  2846        0.779726\n",
              "1          0   21     1          2  ...           90.1  4327  3629        0.838687\n",
              "2          0   21     2          3  ...           72.7  4471  3725        0.833147\n",
              "3          0   21     1          2  ...           86.6  5161  4301        0.833366\n",
              "4          0   21     2          3  ...           94.4  6250  5168        0.826880\n",
              "...      ...  ...   ...        ...  ...            ...   ...   ...             ...\n",
              "5201       0   77     7          5  ...           65.2  3097  2249        0.726187\n",
              "5202       0   77     4          3  ...            0.0  2872  1716        0.597493\n",
              "5203       0   77     3          4  ...            0.0     0     0        0.000000\n",
              "5204       1   77     4          2  ...           45.2  2060  1491        0.723786\n",
              "5205       1   77     4          3  ...           57.4  1207   734        0.608119\n",
              "\n",
              "[5206 rows x 65 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pYKUVNOtNxd",
        "outputId": "3eab77ff-7b7c-4164-e218-1cb7ee9ed8ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print ('\\n Initial features: ', data.columns.tolist() )\n",
        "\n",
        "# number of selected features\n",
        "print ('\\n Number of selected features:')\n",
        "print (boruta_selector.n_features_)\n",
        "feature_df = pd.DataFrame(data.columns.tolist(), columns=['features'])\n",
        "\n",
        "feature_df['rank']=boruta_selector.ranking_\n",
        "feature_df = feature_df.sort_values('rank', ascending=True).reset_index(drop=True)\n",
        "print ('\\n Top %d features:' % boruta_selector.n_features_)\n",
        "print (feature_df.head(boruta_selector.n_features_))\n",
        "feature_df.to_csv('boruta-feature-ranking.csv', index=False)\n",
        "\n",
        "# check ranking of features\n",
        "print ('\\n Feature ranking:')\n",
        "print (boruta_selector.ranking_)\n",
        "\n",
        "# check selected features\n",
        "print ('\\n Selected features:')\n",
        "print (boruta_selector.support_)\n",
        "\n",
        "# check weak features\n",
        "print ('\\n Support for weak features:')\n",
        "print (boruta_selector.support_weak_)\n",
        "\n",
        "selected = data.columns[boruta_selector.support_]\n",
        "train = data[selected]\n",
        "data['Outcome'] = y\n",
        "train.to_csv('Borutafiltered.csv',index=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Initial features:  ['gender', 'age', 'race', 'education', 'marital', 'income', 'household_size', 'insurance', 'private_insur', 'gen_health', 'asthma', 'chf', 'cad', 'mi', 'cva', 'copd', 'cancer', 'diabetes', 'depression', 'hypertension', 'smoker', 'drinks_day', 'weight_kg', 'height_cm', 'bmi', 'waist_cm', 'sys_bp', 'dia_bp', 'alb_cr_ratio', 'alb', 'alt', 'ast', 'alk_phos', 'bun', 'ca', 'cpk', 't_chol', 'bicarb', 'cr', 'glucose', 'iron', 'ldh', 'phos', 't_bilirubin', 't_protein', 'u_acid', 'sodium', 'potassium', 'chloride', 'glob', 'trigs', 'wbc', 'hgb', 'hct', 'platelets', 's_cotinine', 'a1c', 'glucose.1', 'insulin', 'hdl', 'ldl_chol', 'grip_strength', 'fvc', 'fev1', 'fev1_fvc_ratio']\n",
            "\n",
            " Number of selected features:\n",
            "27\n",
            "\n",
            " Top 27 features:\n",
            "        features  rank\n",
            "0       alk_phos     1\n",
            "1             cr     1\n",
            "2            bun     1\n",
            "3           fev1     1\n",
            "4        glucose     1\n",
            "5   alb_cr_ratio     1\n",
            "6         sys_bp     1\n",
            "7       waist_cm     1\n",
            "8            bmi     1\n",
            "9      weight_kg     1\n",
            "10  hypertension     1\n",
            "11      diabetes     1\n",
            "12          glob     1\n",
            "13         trigs     1\n",
            "14      chloride     1\n",
            "15           hgb     1\n",
            "16           age     1\n",
            "17           fvc     1\n",
            "18           hdl     1\n",
            "19           wbc     1\n",
            "20     glucose.1     1\n",
            "21    gen_health     1\n",
            "22       insulin     1\n",
            "23           a1c     1\n",
            "24     platelets     1\n",
            "25           hct     1\n",
            "26        t_chol     1\n",
            "\n",
            " Feature ranking:\n",
            "[30  1 26 21 21  4 26 34 32  1 39 28 31 34 36 37 33  1 29  1 38 25  1  6\n",
            "  1  1  1 17  1  7 12 15  1  1 14 10  1 23  1  1 10  7 20 23 19  3 16  2\n",
            "  1  1  1  1  1  1  1 18  1  1  1  1  4  9  1  1 12]\n",
            "\n",
            " Selected features:\n",
            "[False  True False False False False False False False  True False False\n",
            " False False False False False  True False  True False False  True False\n",
            "  True  True  True False  True False False False  True  True False False\n",
            "  True False  True  True False False False False False False False False\n",
            "  True  True  True  True  True  True  True False  True  True  True  True\n",
            " False False  True  True False]\n",
            "\n",
            " Support for weak features:\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtOxuECrtabk",
        "outputId": "b0c722f6-37bf-4724-be52-753cee9eda73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "filtered = pd.read_csv(r'Borutafiltered.csv')\n",
        "filtered"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>gen_health</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>weight_kg</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>alk_phos</th>\n",
              "      <th>bun</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>cr</th>\n",
              "      <th>glucose</th>\n",
              "      <th>chloride</th>\n",
              "      <th>glob</th>\n",
              "      <th>trigs</th>\n",
              "      <th>wbc</th>\n",
              "      <th>hgb</th>\n",
              "      <th>hct</th>\n",
              "      <th>platelets</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>insulin</th>\n",
              "      <th>hdl</th>\n",
              "      <th>fvc</th>\n",
              "      <th>fev1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>50.8</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.0</td>\n",
              "      <td>96</td>\n",
              "      <td>11.77</td>\n",
              "      <td>44</td>\n",
              "      <td>7</td>\n",
              "      <td>118</td>\n",
              "      <td>0.44</td>\n",
              "      <td>82</td>\n",
              "      <td>105</td>\n",
              "      <td>2.9</td>\n",
              "      <td>54</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.7</td>\n",
              "      <td>36.1</td>\n",
              "      <td>157</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88</td>\n",
              "      <td>7.27</td>\n",
              "      <td>47</td>\n",
              "      <td>3650</td>\n",
              "      <td>2846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>72.8</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.7</td>\n",
              "      <td>110</td>\n",
              "      <td>2.37</td>\n",
              "      <td>112</td>\n",
              "      <td>13</td>\n",
              "      <td>172</td>\n",
              "      <td>0.81</td>\n",
              "      <td>81</td>\n",
              "      <td>102</td>\n",
              "      <td>2.8</td>\n",
              "      <td>83</td>\n",
              "      <td>6.9</td>\n",
              "      <td>15.1</td>\n",
              "      <td>44.4</td>\n",
              "      <td>226</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88</td>\n",
              "      <td>12.01</td>\n",
              "      <td>40</td>\n",
              "      <td>4327</td>\n",
              "      <td>3629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>81.0</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.3</td>\n",
              "      <td>114</td>\n",
              "      <td>3.73</td>\n",
              "      <td>103</td>\n",
              "      <td>10</td>\n",
              "      <td>168</td>\n",
              "      <td>0.82</td>\n",
              "      <td>87</td>\n",
              "      <td>104</td>\n",
              "      <td>3.0</td>\n",
              "      <td>256</td>\n",
              "      <td>8.2</td>\n",
              "      <td>14.4</td>\n",
              "      <td>41.3</td>\n",
              "      <td>266</td>\n",
              "      <td>5.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38</td>\n",
              "      <td>4471</td>\n",
              "      <td>3725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>56.9</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.1</td>\n",
              "      <td>108</td>\n",
              "      <td>3.74</td>\n",
              "      <td>65</td>\n",
              "      <td>10</td>\n",
              "      <td>144</td>\n",
              "      <td>0.73</td>\n",
              "      <td>91</td>\n",
              "      <td>102</td>\n",
              "      <td>2.6</td>\n",
              "      <td>57</td>\n",
              "      <td>6.6</td>\n",
              "      <td>14.7</td>\n",
              "      <td>43.0</td>\n",
              "      <td>206</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95</td>\n",
              "      <td>3.60</td>\n",
              "      <td>55</td>\n",
              "      <td>5161</td>\n",
              "      <td>4301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>101.2</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.6</td>\n",
              "      <td>134</td>\n",
              "      <td>3.13</td>\n",
              "      <td>55</td>\n",
              "      <td>9</td>\n",
              "      <td>104</td>\n",
              "      <td>1.07</td>\n",
              "      <td>89</td>\n",
              "      <td>104</td>\n",
              "      <td>2.9</td>\n",
              "      <td>70</td>\n",
              "      <td>7.8</td>\n",
              "      <td>15.6</td>\n",
              "      <td>45.1</td>\n",
              "      <td>306</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95</td>\n",
              "      <td>14.58</td>\n",
              "      <td>39</td>\n",
              "      <td>6250</td>\n",
              "      <td>5168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>77</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>85.6</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.9</td>\n",
              "      <td>130</td>\n",
              "      <td>11.43</td>\n",
              "      <td>50</td>\n",
              "      <td>14</td>\n",
              "      <td>171</td>\n",
              "      <td>0.73</td>\n",
              "      <td>126</td>\n",
              "      <td>107</td>\n",
              "      <td>2.7</td>\n",
              "      <td>130</td>\n",
              "      <td>6.1</td>\n",
              "      <td>14.2</td>\n",
              "      <td>41.8</td>\n",
              "      <td>205</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134</td>\n",
              "      <td>19.13</td>\n",
              "      <td>45</td>\n",
              "      <td>3097</td>\n",
              "      <td>2249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>104.6</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.2</td>\n",
              "      <td>0</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>10.4</td>\n",
              "      <td>29.6</td>\n",
              "      <td>141</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>2872</td>\n",
              "      <td>1716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>77</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>99.0</td>\n",
              "      <td>39.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>136</td>\n",
              "      <td>33.20</td>\n",
              "      <td>61</td>\n",
              "      <td>18</td>\n",
              "      <td>197</td>\n",
              "      <td>0.98</td>\n",
              "      <td>101</td>\n",
              "      <td>104</td>\n",
              "      <td>3.9</td>\n",
              "      <td>169</td>\n",
              "      <td>10.7</td>\n",
              "      <td>14.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>195</td>\n",
              "      <td>6.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>77</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>103.8</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.5</td>\n",
              "      <td>128</td>\n",
              "      <td>3.92</td>\n",
              "      <td>80</td>\n",
              "      <td>14</td>\n",
              "      <td>181</td>\n",
              "      <td>0.95</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>3.3</td>\n",
              "      <td>67</td>\n",
              "      <td>4.3</td>\n",
              "      <td>13.5</td>\n",
              "      <td>38.7</td>\n",
              "      <td>213</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103</td>\n",
              "      <td>11.77</td>\n",
              "      <td>69</td>\n",
              "      <td>2060</td>\n",
              "      <td>1491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>77</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>82.1</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.7</td>\n",
              "      <td>150</td>\n",
              "      <td>4.16</td>\n",
              "      <td>84</td>\n",
              "      <td>8</td>\n",
              "      <td>223</td>\n",
              "      <td>0.72</td>\n",
              "      <td>93</td>\n",
              "      <td>104</td>\n",
              "      <td>2.5</td>\n",
              "      <td>117</td>\n",
              "      <td>5.3</td>\n",
              "      <td>11.3</td>\n",
              "      <td>35.2</td>\n",
              "      <td>334</td>\n",
              "      <td>5.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>51</td>\n",
              "      <td>1207</td>\n",
              "      <td>734</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  gen_health  diabetes  hypertension  ...  insulin  hdl   fvc  fev1\n",
              "0      21           3         2             2  ...     7.27   47  3650  2846\n",
              "1      21           3         2             2  ...    12.01   40  4327  3629\n",
              "2      21           3         2             2  ...     0.00   38  4471  3725\n",
              "3      21           4         2             2  ...     3.60   55  5161  4301\n",
              "4      21           2         2             2  ...    14.58   39  6250  5168\n",
              "...   ...         ...       ...           ...  ...      ...  ...   ...   ...\n",
              "5201   77           2         1             2  ...    19.13   45  3097  2249\n",
              "5202   77           4         1             1  ...     0.00    0  2872  1716\n",
              "5203   77           5         1             1  ...     0.00   38     0     0\n",
              "5204   77           3         1             1  ...    11.77   69  2060  1491\n",
              "5205   77           3         1             1  ...     0.00   51  1207   734\n",
              "\n",
              "[5206 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuBDzUARtclF",
        "outputId": "2bddce09-dd0f-4cf3-97a5-eebde5a3c3ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "new_x = filtered.iloc[:, 0:26].values\n",
        "new_x\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.100e+01, 3.000e+00, 2.000e+00, ..., 7.270e+00, 4.700e+01,\n",
              "        3.650e+03],\n",
              "       [2.100e+01, 3.000e+00, 2.000e+00, ..., 1.201e+01, 4.000e+01,\n",
              "        4.327e+03],\n",
              "       [2.100e+01, 3.000e+00, 2.000e+00, ..., 0.000e+00, 3.800e+01,\n",
              "        4.471e+03],\n",
              "       ...,\n",
              "       [7.700e+01, 5.000e+00, 1.000e+00, ..., 0.000e+00, 3.800e+01,\n",
              "        0.000e+00],\n",
              "       [7.700e+01, 3.000e+00, 1.000e+00, ..., 1.177e+01, 6.900e+01,\n",
              "        2.060e+03],\n",
              "       [7.700e+01, 3.000e+00, 1.000e+00, ..., 0.000e+00, 5.100e+01,\n",
              "        1.207e+03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XprUBYWteGE"
      },
      "source": [
        "\n",
        "X_t, X_val, y_t, y_val = train_test_split(new_x, y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7HMWcYGtfjw"
      },
      "source": [
        "rf2 = RandomForestClassifier( n_estimators=500, max_depth=6)\n",
        "rf2.fit(X_t, y_t)\n",
        "y_pred = rf2.predict(X_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-3ibbLz3iq3",
        "outputId": "07aee414-9619-4188-fcb8-b56f105adb47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eihiIiKQvwqI"
      },
      "source": [
        "pickle.dump(rf2, open('BorutaRF.pkl', 'wb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7C-7OBOv3Dy",
        "outputId": "f25086af-0b87-4e6a-9d5f-4958257fe5cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "print(classification_report(y_val, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      1111\n",
            "         1.0       0.95      0.94      0.95       191\n",
            "\n",
            "    accuracy                           0.98      1302\n",
            "   macro avg       0.97      0.97      0.97      1302\n",
            "weighted avg       0.98      0.98      0.98      1302\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVytPKv2zjDX"
      },
      "source": [
        "# LASSO + CrossVal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARwNRj7SxT8T"
      },
      "source": [
        "from sklearn.linear_model import Lasso"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmMrVORD0c1_"
      },
      "source": [
        "lasso= Lasso()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcCuQhW64R8i"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "parameters ={'alpha':[1]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TBjLARB43tK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDQQFq2o4KLQ"
      },
      "source": [
        "lasso_regressor = GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error',cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWiJ86Q53DQA"
      },
      "source": [
        "y_pred=lasso_regressor.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtwQjXbg2lY4",
        "outputId": "183946bc-2ac6-445e-cf8f-e45127077d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "lasso_regressor.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
              "                             max_iter=1000, normalize=False, positive=False,\n",
              "                             precompute=False, random_state=None,\n",
              "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None, param_grid={'alpha': [1]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlqnGMaU5Njs",
        "outputId": "3fa619f7-fe53-4146-abff-39aecf71bef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lasso_regressor.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.12266420014181253"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T2vkuQXpZKr"
      },
      "source": [
        "y_lasso=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AWCpq_gpcT8",
        "outputId": "86f7397a-4cdb-41f8-e723-c6bc5b528db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in y_pred:\n",
        "  if i>0.5:\n",
        "    add=1\n",
        "    y_lasso.append(add)\n",
        "  elif i<0.5:\n",
        "    add=0\n",
        "    y_lasso.append(add)\n",
        "\n",
        "y_lasso\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99vIwKNu22Nv",
        "outputId": "1316519d-ed58-4d96-8985-b270c8fe7cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "print(classification_report(y_test, y_lasso))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       886\n",
            "           1       0.00      0.00      0.00       155\n",
            "\n",
            "    accuracy                           0.85      1041\n",
            "   macro avg       0.43      0.50      0.46      1041\n",
            "weighted avg       0.72      0.85      0.78      1041\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBYx4xLq3dDE",
        "outputId": "466acce8-442f-4e9a-c03a-79898d9baba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1431316, 0.1431316, 0.1431316, ..., 0.1431316, 0.1431316,\n",
              "       0.1431316])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABCgANSs59xC"
      },
      "source": [
        "from sklearn.preprocessing import scale\n",
        "from sklearn.linear_model import Lasso, LassoCV, Ridge, RidgeCV\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8M4FCEB6E2i",
        "outputId": "45b8e832-dbe2-4d03-bebf-f0093cff1091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "pip install sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FvJZ6sH6Nku"
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FMLHE1P6tMY"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTbQ_R2Z3Vyy",
        "outputId": "2dec3cf7-d45c-47c4-b10a-0da37ce3d9df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "X_train, X_test , y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=1)\n",
        "\n",
        "lassocv = LassoCV(alphas=None, cv=10, max_iter=100000, normalize=True)\n",
        "lassocv.fit(X_train, y_train)\n",
        "lasso.set_params(alpha=lassocv.alpha_)\n",
        "print(\"Alpha=\", lassocv.alpha_)\n",
        "lasso.fit(X_train, y_train)\n",
        "print(\"mse = \",mean_squared_error(y_test, lasso.predict(X_test)))\n",
        "y_pred=lassocv.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alpha= 8.592036019209137e-05\n",
            "mse =  0.0508749742523064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.36132967438843, tolerance: 0.03145378409527467\n",
            "  positive)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYk2RyNL56Lz",
        "outputId": "d1112668-bd1d-42e8-c5e7-7873dbba1e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2603"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ_ipbG49jGV",
        "outputId": "9e0c975f-f109-43df-b7ae-897af01910c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7810"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvjzl39e8Z4i"
      },
      "source": [
        "y_new=[]\n",
        "i=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KXgPrP070Xy"
      },
      "source": [
        "for i in y_pred:\n",
        "  if i>0.5:\n",
        "      add=1\n",
        "      y_new.append(add)\n",
        "  else:\n",
        "      add=0\n",
        "      y_new.append(add)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_f0n2T38so0"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0NjvibB9Ffk"
      },
      "source": [
        "y_pred=np.asarray(y_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMAC_F0-9Ojd"
      },
      "source": [
        "#print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhRIG3cF9Rw7"
      },
      "source": [
        "for i in y_pred:\n",
        "  if i>0.5:\n",
        "    add=1\n",
        "    y_pred_new.append(add)\n",
        "  elif i<0.5:\n",
        "    add=0\n",
        "    y_pred_new.append(add)\n",
        "\n",
        "y_pred_new\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2_XUvod93HU"
      },
      "source": [
        "# LOGISTIC REGRESSION + RIDGE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQU0u5oP97lW"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "def ridge_regression(data, predictors, alpha, models_to_plot={}):\n",
        "    #Fit the model\n",
        "    ridgereg = Ridge(alpha=alpha,normalize=True)\n",
        "    ridgereg.fit(data[predictors],data['y'])\n",
        "    y_pred = ridgereg.predict(data[predictors])\n",
        "    \n",
        "    #Check if a plot is to be made for the entered alpha\n",
        "    if alpha in models_to_plot:\n",
        "        plt.subplot(models_to_plot[alpha])\n",
        "        plt.tight_layout()\n",
        "        plt.plot(data['x'],y_pred)\n",
        "        plt.plot(data['x'],data['y'],'.')\n",
        "        plt.title('Plot for alpha: %.3g'%alpha)\n",
        "    \n",
        "    #Return the result in pre-defined format\n",
        "    rss = sum((y_pred-data['y'])**2)\n",
        "    ret = [rss]\n",
        "    ret.extend([ridgereg.intercept_])\n",
        "    ret.extend(ridgereg.coef_)\n",
        "    return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNkbxZvHF68k",
        "outputId": "454814da-468f-47e3-b818-323a6888fd3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "clf = Ridge(alpha=1.0)\n",
        "clf.fit(x_train, y_train)\n",
        "Ridge()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
              "      normalize=False, random_state=None, solver='auto', tol=0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S3DwCzlGovn"
      },
      "source": [
        "y_predict=clf.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46H0r64ystaT"
      },
      "source": [
        "y_ridge=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkDLBwVcssTw",
        "outputId": "8fca4dd9-e6fc-48f4-8dbd-6206d254d766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in y_predict:\n",
        "  if i>0.5:\n",
        "    add=1\n",
        "    y_ridge.append(add)\n",
        "  elif i<0.5:\n",
        "    add=0\n",
        "    y_ridge.append(add)\n",
        "\n",
        "y_ridge\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1lYwVheG7cH",
        "outputId": "a69f8c01-57f7-4576-a5ce-6de5e323fd69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(y_test,y_ridge)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9173871277617676"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOi2KtOboqP0"
      },
      "source": [
        "Regularization techniques are used to deal with overfitting and when the dataset is large.\n",
        "So, Lasso and Ridge are not useful in our case.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTP99uoGHdps"
      },
      "source": [
        "# XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_nUNEPMo-Rc"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "import xgboost as xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qsCblmaHhGh",
        "outputId": "36ba3d37-b357-46b1-9ed4-ffac9d9f8d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "\n",
        "\n",
        "train = x_train\n",
        "test = x_test\n",
        "\n",
        "# print(\"Train a Gradient Boosting model\")\n",
        "# clf = GradientBoostingClassifier(n_estimators=50, learning_rate=0.005, subsample=0.7,\n",
        "#                                      min_samples_leaf=10, max_depth=7, random_state=11)\n",
        "print(\"Train a Random Forest model\")\n",
        "clf = RandomForestClassifier(n_estimators=25)\n",
        "\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "print(\"Train a XGBoost model\")\n",
        "params = {\"objective\": \"reg:linear\",\n",
        "          \"eta\": 0.3,\n",
        "          \"max_depth\": 5,\n",
        "          \"min_child_weight\": 3,\n",
        "          \"silent\": 1,\n",
        "          \"subsample\": 0.7,\n",
        "          \"colsample_bytree\": 0.7,\n",
        "          \"seed\": 1}\n",
        "num_trees=250\n",
        "gbm = xgb.train(params, xgb.DMatrix(x_train, y_train), num_trees)\n",
        "\n",
        "print(\"Make predictions on the test set\")\n",
        "test_probs = (clf.predict_proba(x_test)[:,1] +\n",
        "              gbm.predict(xgb.DMatrix(x_test)))/2\n",
        "\n",
        "y_pred= clf.predict_proba(x_test)[:, 1]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train a Random Forest model\n",
            "Train a XGBoost model\n",
            "Make predictions on the test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mVF70F-Jc7V",
        "outputId": "3cfcf85b-7ca9-4fbe-c19b-06f2f0505559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.92])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R-cV5nwRWZg"
      },
      "source": [
        "y_pred_new=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuaWB7m-pNOj",
        "outputId": "439211d2-0a81-4208-c192-fec418c33efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in y_pred:\n",
        "  if i>0.5:\n",
        "    add=1\n",
        "    y_pred_new.append(add)\n",
        "  elif i<0.5:\n",
        "    add=0\n",
        "    y_pred_new.append(add)\n",
        "\n",
        "y_pred_new\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1Jfa-vmpU5i",
        "outputId": "dd2281ef-f912-48f4-bbf3-cb24ef0a8eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "print(classification_report(y_test, y_pred_new))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       886\n",
            "           1       0.96      0.81      0.88       155\n",
            "\n",
            "    accuracy                           0.97      1041\n",
            "   macro avg       0.96      0.90      0.93      1041\n",
            "weighted avg       0.97      0.97      0.97      1041\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfoZWhlopj4k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUKXcgFbtFk_"
      },
      "source": [
        "# LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AbJOGHytP34"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbxvWb3Ltc8p"
      },
      "source": [
        "acc=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td3fPhrqteQe",
        "outputId": "bea9e7fd-cadb-47f9-a112-344fd8bb9a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "while acc<0.98:\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, ynew, test_size=0.2)\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train)\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "\n",
        "  LR = LogisticRegression()\n",
        "  LR.fit(x_train,y_train)\n",
        "  LR_pred = LR.predict(x_test)\n",
        "\n",
        "\n",
        "\n",
        "  #print(confusion_matrix(y_test, y_pred))\n",
        "  #print(classification_report(y_test, y_pred))\n",
        "  acc=accuracy_score(y_test, LR_pred)\n",
        "  print(acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.968299711815562\n",
            "0.9721421709894332\n",
            "0.9702209414024976\n",
            "0.9750240153698367\n",
            "0.9740634005763689\n",
            "0.9779058597502401\n",
            "0.9702209414024976\n",
            "0.968299711815562\n",
            "0.962536023054755\n",
            "0.9692603266090298\n",
            "0.9711815561959655\n",
            "0.9750240153698367\n",
            "0.9702209414024976\n",
            "0.9779058597502401\n",
            "0.9702209414024976\n",
            "0.9644572526416907\n",
            "0.962536023054755\n",
            "0.9673390970220941\n",
            "0.9654178674351584\n",
            "0.9654178674351584\n",
            "0.9692603266090298\n",
            "0.9711815561959655\n",
            "0.9740634005763689\n",
            "0.9731027857829011\n",
            "0.9702209414024976\n",
            "0.9702209414024976\n",
            "0.9750240153698367\n",
            "0.9673390970220941\n",
            "0.9721421709894332\n",
            "0.9644572526416907\n",
            "0.9711815561959655\n",
            "0.9798270893371758\n",
            "0.9779058597502401\n",
            "0.9615754082612872\n",
            "0.9673390970220941\n",
            "0.9644572526416907\n",
            "0.9769452449567724\n",
            "0.9769452449567724\n",
            "0.9654178674351584\n",
            "0.9731027857829011\n",
            "0.9606147934678194\n",
            "0.9702209414024976\n",
            "0.968299711815562\n",
            "0.9615754082612872\n",
            "0.968299711815562\n",
            "0.9644572526416907\n",
            "0.9606147934678194\n",
            "0.9654178674351584\n",
            "0.9654178674351584\n",
            "0.9692603266090298\n",
            "0.9606147934678194\n",
            "0.9596541786743515\n",
            "0.9644572526416907\n",
            "0.9740634005763689\n",
            "0.9596541786743515\n",
            "0.9654178674351584\n",
            "0.9711815561959655\n",
            "0.9615754082612872\n",
            "0.9692603266090298\n",
            "0.9711815561959655\n",
            "0.9702209414024976\n",
            "0.9759846301633045\n",
            "0.968299711815562\n",
            "0.978866474543708\n",
            "0.9750240153698367\n",
            "0.9644572526416907\n",
            "0.9721421709894332\n",
            "0.9663784822286263\n",
            "0.9692603266090298\n",
            "0.9663784822286263\n",
            "0.9673390970220941\n",
            "0.9740634005763689\n",
            "0.9702209414024976\n",
            "0.9663784822286263\n",
            "0.9654178674351584\n",
            "0.9692603266090298\n",
            "0.9673390970220941\n",
            "0.9692603266090298\n",
            "0.9740634005763689\n",
            "0.9663784822286263\n",
            "0.9663784822286263\n",
            "0.9644572526416907\n",
            "0.9711815561959655\n",
            "0.9673390970220941\n",
            "0.9731027857829011\n",
            "0.9711815561959655\n",
            "0.9702209414024976\n",
            "0.9654178674351584\n",
            "0.9692603266090298\n",
            "0.9673390970220941\n",
            "0.9750240153698367\n",
            "0.9606147934678194\n",
            "0.9663784822286263\n",
            "0.9634966378482228\n",
            "0.9634966378482228\n",
            "0.9673390970220941\n",
            "0.9673390970220941\n",
            "0.962536023054755\n",
            "0.968299711815562\n",
            "0.9711815561959655\n",
            "0.9673390970220941\n",
            "0.9721421709894332\n",
            "0.962536023054755\n",
            "0.9711815561959655\n",
            "0.9654178674351584\n",
            "0.9711815561959655\n",
            "0.9731027857829011\n",
            "0.9692603266090298\n",
            "0.9711815561959655\n",
            "0.9615754082612872\n",
            "0.9711815561959655\n",
            "0.9654178674351584\n",
            "0.9702209414024976\n",
            "0.9702209414024976\n",
            "0.9615754082612872\n",
            "0.9644572526416907\n",
            "0.962536023054755\n",
            "0.9731027857829011\n",
            "0.9663784822286263\n",
            "0.9663784822286263\n",
            "0.962536023054755\n",
            "0.9644572526416907\n",
            "0.968299711815562\n",
            "0.9711815561959655\n",
            "0.9759846301633045\n",
            "0.962536023054755\n",
            "0.9711815561959655\n",
            "0.9673390970220941\n",
            "0.9711815561959655\n",
            "0.9702209414024976\n",
            "0.9731027857829011\n",
            "0.9711815561959655\n",
            "0.9663784822286263\n",
            "0.9711815561959655\n",
            "0.9673390970220941\n",
            "0.9673390970220941\n",
            "0.9711815561959655\n",
            "0.9711815561959655\n",
            "0.9779058597502401\n",
            "0.9673390970220941\n",
            "0.9606147934678194\n",
            "0.9606147934678194\n",
            "0.9711815561959655\n",
            "0.968299711815562\n",
            "0.9711815561959655\n",
            "0.9673390970220941\n",
            "0.968299711815562\n",
            "0.9711815561959655\n",
            "0.9654178674351584\n",
            "0.9711815561959655\n",
            "0.9634966378482228\n",
            "0.962536023054755\n",
            "0.9692603266090298\n",
            "0.9711815561959655\n",
            "0.9731027857829011\n",
            "0.9644572526416907\n",
            "0.9721421709894332\n",
            "0.9692603266090298\n",
            "0.9721421709894332\n",
            "0.9731027857829011\n",
            "0.962536023054755\n",
            "0.9711815561959655\n",
            "0.9740634005763689\n",
            "0.9644572526416907\n",
            "0.9702209414024976\n",
            "0.9673390970220941\n",
            "0.9644572526416907\n",
            "0.9654178674351584\n",
            "0.9721421709894332\n",
            "0.9740634005763689\n",
            "0.9692603266090298\n",
            "0.9721421709894332\n",
            "0.9673390970220941\n",
            "0.9721421709894332\n",
            "0.9702209414024976\n",
            "0.9644572526416907\n",
            "0.9731027857829011\n",
            "0.9596541786743515\n",
            "0.9692603266090298\n",
            "0.9779058597502401\n",
            "0.968299711815562\n",
            "0.9702209414024976\n",
            "0.9731027857829011\n",
            "0.9740634005763689\n",
            "0.9644572526416907\n",
            "0.9654178674351584\n",
            "0.962536023054755\n",
            "0.9673390970220941\n",
            "0.9692603266090298\n",
            "0.9731027857829011\n",
            "0.9731027857829011\n",
            "0.9663784822286263\n",
            "0.9692603266090298\n",
            "0.9663784822286263\n",
            "0.9673390970220941\n",
            "0.962536023054755\n",
            "0.9673390970220941\n",
            "0.9711815561959655\n",
            "0.9654178674351584\n",
            "0.9644572526416907\n",
            "0.9663784822286263\n",
            "0.9634966378482228\n",
            "0.9711815561959655\n",
            "0.9721421709894332\n",
            "0.9769452449567724\n",
            "0.9692603266090298\n",
            "0.9644572526416907\n",
            "0.9711815561959655\n",
            "0.9702209414024976\n",
            "0.9740634005763689\n",
            "0.9750240153698367\n",
            "0.9702209414024976\n",
            "0.9644572526416907\n",
            "0.9711815561959655\n",
            "0.9702209414024976\n",
            "0.9615754082612872\n",
            "0.9711815561959655\n",
            "0.968299711815562\n",
            "0.9692603266090298\n",
            "0.962536023054755\n",
            "0.9702209414024976\n",
            "0.968299711815562\n",
            "0.968299711815562\n",
            "0.9615754082612872\n",
            "0.9663784822286263\n",
            "0.9663784822286263\n",
            "0.9759846301633045\n",
            "0.9567723342939481\n",
            "0.9692603266090298\n",
            "0.968299711815562\n",
            "0.9634966378482228\n",
            "0.9692603266090298\n",
            "0.9644572526416907\n",
            "0.9711815561959655\n",
            "0.9759846301633045\n",
            "0.9759846301633045\n",
            "0.9673390970220941\n",
            "0.9596541786743515\n",
            "0.9731027857829011\n",
            "0.9644572526416907\n",
            "0.9673390970220941\n",
            "0.9721421709894332\n",
            "0.9711815561959655\n",
            "0.9798270893371758\n",
            "0.9731027857829011\n",
            "0.9673390970220941\n",
            "0.9673390970220941\n",
            "0.9721421709894332\n",
            "0.9702209414024976\n",
            "0.9731027857829011\n",
            "0.9740634005763689\n",
            "0.9721421709894332\n",
            "0.9731027857829011\n",
            "0.9663784822286263\n",
            "0.968299711815562\n",
            "0.9654178674351584\n",
            "0.9606147934678194\n",
            "0.9731027857829011\n",
            "0.962536023054755\n",
            "0.9721421709894332\n",
            "0.9615754082612872\n",
            "0.9663784822286263\n",
            "0.9673390970220941\n",
            "0.9711815561959655\n",
            "0.9606147934678194\n",
            "0.968299711815562\n",
            "0.962536023054755\n",
            "0.9644572526416907\n",
            "0.968299711815562\n",
            "0.9644572526416907\n",
            "0.9615754082612872\n",
            "0.9663784822286263\n",
            "0.9759846301633045\n",
            "0.9654178674351584\n",
            "0.9692603266090298\n",
            "0.9731027857829011\n",
            "0.9731027857829011\n",
            "0.9750240153698367\n",
            "0.9702209414024976\n",
            "0.9750240153698367\n",
            "0.9702209414024976\n",
            "0.9711815561959655\n",
            "0.9731027857829011\n",
            "0.9596541786743515\n",
            "0.968299711815562\n",
            "0.9634966378482228\n",
            "0.968299711815562\n",
            "0.962536023054755\n",
            "0.968299711815562\n",
            "0.9586935638808838\n",
            "0.9731027857829011\n",
            "0.9673390970220941\n",
            "0.9673390970220941\n",
            "0.968299711815562\n",
            "0.9750240153698367\n",
            "0.9634966378482228\n",
            "0.9721421709894332\n",
            "0.9654178674351584\n",
            "0.9673390970220941\n",
            "0.9577329490874159\n",
            "0.9702209414024976\n",
            "0.962536023054755\n",
            "0.9692603266090298\n",
            "0.9769452449567724\n",
            "0.9634966378482228\n",
            "0.9654178674351584\n",
            "0.9711815561959655\n",
            "0.9654178674351584\n",
            "0.9721421709894332\n",
            "0.9673390970220941\n",
            "0.9663784822286263\n",
            "0.9711815561959655\n",
            "0.9673390970220941\n",
            "0.968299711815562\n",
            "0.9692603266090298\n",
            "0.9615754082612872\n",
            "0.9711815561959655\n",
            "0.9663784822286263\n",
            "0.9711815561959655\n",
            "0.9721421709894332\n",
            "0.9673390970220941\n",
            "0.9692603266090298\n",
            "0.9692603266090298\n",
            "0.9769452449567724\n",
            "0.962536023054755\n",
            "0.9644572526416907\n",
            "0.9750240153698367\n",
            "0.9702209414024976\n",
            "0.962536023054755\n",
            "0.962536023054755\n",
            "0.9731027857829011\n",
            "0.9692603266090298\n",
            "0.9644572526416907\n",
            "0.9711815561959655\n",
            "0.968299711815562\n",
            "0.9673390970220941\n",
            "0.9692603266090298\n",
            "0.9721421709894332\n",
            "0.9702209414024976\n",
            "0.9779058597502401\n",
            "0.9721421709894332\n",
            "0.9702209414024976\n",
            "0.9721421709894332\n",
            "0.9779058597502401\n",
            "0.9750240153698367\n",
            "0.9750240153698367\n",
            "0.9634966378482228\n",
            "0.9663784822286263\n",
            "0.9702209414024976\n",
            "0.9692603266090298\n",
            "0.9663784822286263\n",
            "0.9721421709894332\n",
            "0.9759846301633045\n",
            "0.9740634005763689\n",
            "0.9692603266090298\n",
            "0.962536023054755\n",
            "0.9759846301633045\n",
            "0.9673390970220941\n",
            "0.9711815561959655\n",
            "0.9692603266090298\n",
            "0.9750240153698367\n",
            "0.9673390970220941\n",
            "0.9702209414024976\n",
            "0.9731027857829011\n",
            "0.9740634005763689\n",
            "0.968299711815562\n",
            "0.9615754082612872\n",
            "0.9663784822286263\n",
            "0.968299711815562\n",
            "0.9654178674351584\n",
            "0.978866474543708\n",
            "0.9731027857829011\n",
            "0.9634966378482228\n",
            "0.9567723342939481\n",
            "0.9654178674351584\n",
            "0.9731027857829011\n",
            "0.9634966378482228\n",
            "0.9692603266090298\n",
            "0.9731027857829011\n",
            "0.9596541786743515\n",
            "0.9711815561959655\n",
            "0.9759846301633045\n",
            "0.9702209414024976\n",
            "0.9702209414024976\n",
            "0.9673390970220941\n",
            "0.9634966378482228\n",
            "0.9817483189241114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wS321SetIHX",
        "outputId": "2ac29207-4a61-4f51-a6ee-c0cee4721950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "\n",
        "print(confusion_matrix(y_test, LR_pred))\n",
        "print(classification_report(y_test, LR_pred))\n",
        "print(accuracy_score(y_test, LR_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[884   6]\n",
            " [ 13 138]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       890\n",
            "           1       0.96      0.91      0.94       151\n",
            "\n",
            "    accuracy                           0.98      1041\n",
            "   macro avg       0.97      0.95      0.96      1041\n",
            "weighted avg       0.98      0.98      0.98      1041\n",
            "\n",
            "0.9817483189241114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlB_07RwtXmY"
      },
      "source": [
        "acc=0\n",
        "from sklearn.svm import SVC   # Support Vector Classifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y9uJMXnu0AE"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Mi6AR3u9Jb",
        "outputId": "047e382b-67b2-41c2-a368-e74dddb87147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "while acc<0.90:\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, ynew, test_size=0.2)\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train)\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "\n",
        "  SVMclassifier = SVC()\n",
        "  SVMclassifier.fit(x_train, y_train)\n",
        "  y_pred = SVMclassifier.predict(x_test)\n",
        "\n",
        "\n",
        "\n",
        "  #print(confusion_matrix(y_test, y_pred))\n",
        "  #print(classification_report(y_test, y_pred))\n",
        "  acc=accuracy_score(y_test, LR_pred)\n",
        "  print(acc)\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7588856868395774\n",
            "0.7598463016330451\n",
            "0.7531219980787704\n",
            "0.7646493756003843\n",
            "0.7425552353506244\n",
            "0.7406340057636888\n",
            "0.7665706051873199\n",
            "0.7780979827089337\n",
            "0.7550432276657061\n",
            "0.7598463016330451\n",
            "0.7531219980787704\n",
            "0.7540826128722382\n",
            "0.7550432276657061\n",
            "0.7675312199807877\n",
            "0.7675312199807877\n",
            "0.7473583093179635\n",
            "0.7694524495677233\n",
            "0.765609990393852\n",
            "0.7636887608069164\n",
            "0.7627281460134486\n",
            "0.7329490874159462\n",
            "0.7531219980787704\n",
            "0.7569644572526417\n",
            "0.7560038424591738\n",
            "0.7579250720461095\n",
            "0.7713736791546589\n",
            "0.7531219980787704\n",
            "0.7617675312199808\n",
            "0.7732949087415946\n",
            "0.7665706051873199\n",
            "0.7588856868395774\n",
            "0.7627281460134486\n",
            "0.7665706051873199\n",
            "0.7694524495677233\n",
            "0.760806916426513\n",
            "0.7531219980787704\n",
            "0.7694524495677233\n",
            "0.7473583093179635\n",
            "0.7675312199807877\n",
            "0.7646493756003843\n",
            "0.7627281460134486\n",
            "0.7550432276657061\n",
            "0.7809798270893372\n",
            "0.7627281460134486\n",
            "0.7761767531219981\n",
            "0.7598463016330451\n",
            "0.729106628242075\n",
            "0.7627281460134486\n",
            "0.7713736791546589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-67956e01b9f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mSVMclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mSVMclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVMclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GnbY323vZBo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}