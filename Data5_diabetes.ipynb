{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data5_diabetes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1LW8BCuW2n9Y1lVFuzvji",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mefy-Aruna/DIABETES_NEW/blob/main/Data5_diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0d1BQY9Jfrs"
      },
      "source": [
        "import pandas as pd\n",
        "# import libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df = pd.read_csv(r'data5.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCJl_o0j3VIX"
      },
      "source": [
        "\n",
        "# Import our libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "import seaborn as sns\n",
        "sns.set(style=\"ticks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jLsjf_nJrDS",
        "outputId": "d31011cf-41c9-4d4b-91be-bf841b0e9186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "x = df.iloc[:, 0:14].values\n",
        "y = df.iloc[:, 14].values\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[193.  ,  77.  ,  49.  , ...,  32.  ,  38.  ,   0.84],\n",
              "       [146.  ,  79.  ,  41.  , ...,  33.  ,  40.  ,   0.83],\n",
              "       [217.  ,  75.  ,  54.  , ...,  40.  ,  45.  ,   0.89],\n",
              "       ...,\n",
              "       [301.  ,  90.  , 118.  , ...,  31.  ,  41.  ,   0.76],\n",
              "       [232.  , 184.  , 114.  , ...,  35.  ,  38.  ,   0.92],\n",
              "       [165.  ,  94.  ,  69.  , ...,  51.  ,  51.  ,   1.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jamg2dT7J45_",
        "outputId": "41ca1395-081b-462b-d7a2-e587655e3576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "x = df.iloc[:, :-1].values\n",
        "x\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[193.  ,  77.  ,  49.  , ...,  32.  ,  38.  ,   0.84],\n",
              "       [146.  ,  79.  ,  41.  , ...,  33.  ,  40.  ,   0.83],\n",
              "       [217.  ,  75.  ,  54.  , ...,  40.  ,  45.  ,   0.89],\n",
              "       ...,\n",
              "       [301.  ,  90.  , 118.  , ...,  31.  ,  41.  ,   0.76],\n",
              "       [232.  , 184.  , 114.  , ...,  35.  ,  38.  ,   0.92],\n",
              "       [165.  ,  94.  ,  69.  , ...,  51.  ,  51.  ,   1.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK8RtVpUaX8M"
      },
      "source": [
        "acc=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G76Ol1c3z7OQ"
      },
      "source": [
        "# Train Test Split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGSCV4pE2adB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePGthJ4PJuuX",
        "outputId": "036125e0-5f8f-479d-9b07-bef99d1b68fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "while acc<0.95:\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "# Preprocessing\n",
        "########################## try without splitting the data\n",
        "\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train)\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  RFclassifier = RandomForestClassifier(n_estimators = 200,random_state=0,warm_start=True)\n",
        "  RFclassifier.fit(x_train, y_train)\n",
        "  y_pred = RFclassifier.predict(x_test)\n",
        "  #print(confusion_matrix(y_test, y_pred))\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  acc=accuracy_score(y_test, y_pred)\n",
        "  print(acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94        66\n",
            "           1       0.75      0.50      0.60        12\n",
            "\n",
            "    accuracy                           0.90        78\n",
            "   macro avg       0.83      0.73      0.77        78\n",
            "weighted avg       0.89      0.90      0.89        78\n",
            "\n",
            "0.8974358974358975\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93        61\n",
            "           1       0.79      0.65      0.71        17\n",
            "\n",
            "    accuracy                           0.88        78\n",
            "   macro avg       0.85      0.80      0.82        78\n",
            "weighted avg       0.88      0.88      0.88        78\n",
            "\n",
            "0.8846153846153846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93        66\n",
            "           1       0.67      0.50      0.57        12\n",
            "\n",
            "    accuracy                           0.88        78\n",
            "   macro avg       0.79      0.73      0.75        78\n",
            "weighted avg       0.88      0.88      0.88        78\n",
            "\n",
            "0.8846153846153846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.91        60\n",
            "           1       0.82      0.50      0.62        18\n",
            "\n",
            "    accuracy                           0.86        78\n",
            "   macro avg       0.84      0.73      0.77        78\n",
            "weighted avg       0.85      0.86      0.85        78\n",
            "\n",
            "0.8589743589743589\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96        67\n",
            "           1       0.75      0.82      0.78        11\n",
            "\n",
            "    accuracy                           0.94        78\n",
            "   macro avg       0.86      0.89      0.87        78\n",
            "weighted avg       0.94      0.94      0.94        78\n",
            "\n",
            "0.9358974358974359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96        68\n",
            "           1       1.00      0.50      0.67        10\n",
            "\n",
            "    accuracy                           0.94        78\n",
            "   macro avg       0.97      0.75      0.82        78\n",
            "weighted avg       0.94      0.94      0.93        78\n",
            "\n",
            "0.9358974358974359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.99      0.96        67\n",
            "           1       0.86      0.55      0.67        11\n",
            "\n",
            "    accuracy                           0.92        78\n",
            "   macro avg       0.89      0.77      0.81        78\n",
            "weighted avg       0.92      0.92      0.92        78\n",
            "\n",
            "0.9230769230769231\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.99      0.95        68\n",
            "           1       0.80      0.40      0.53        10\n",
            "\n",
            "    accuracy                           0.91        78\n",
            "   macro avg       0.86      0.69      0.74        78\n",
            "weighted avg       0.90      0.91      0.90        78\n",
            "\n",
            "0.9102564102564102\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95        69\n",
            "           1       0.60      0.67      0.63         9\n",
            "\n",
            "    accuracy                           0.91        78\n",
            "   macro avg       0.78      0.80      0.79        78\n",
            "weighted avg       0.91      0.91      0.91        78\n",
            "\n",
            "0.9102564102564102\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96        65\n",
            "           1       1.00      0.62      0.76        13\n",
            "\n",
            "    accuracy                           0.94        78\n",
            "   macro avg       0.96      0.81      0.86        78\n",
            "weighted avg       0.94      0.94      0.93        78\n",
            "\n",
            "0.9358974358974359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94        67\n",
            "           1       0.71      0.45      0.56        11\n",
            "\n",
            "    accuracy                           0.90        78\n",
            "   macro avg       0.81      0.71      0.75        78\n",
            "weighted avg       0.89      0.90      0.89        78\n",
            "\n",
            "0.8974358974358975\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94        69\n",
            "           1       0.50      0.33      0.40         9\n",
            "\n",
            "    accuracy                           0.88        78\n",
            "   macro avg       0.71      0.64      0.67        78\n",
            "weighted avg       0.87      0.88      0.87        78\n",
            "\n",
            "0.8846153846153846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95        67\n",
            "           1       0.75      0.55      0.63        11\n",
            "\n",
            "    accuracy                           0.91        78\n",
            "   macro avg       0.84      0.76      0.79        78\n",
            "weighted avg       0.90      0.91      0.90        78\n",
            "\n",
            "0.9102564102564102\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.96        67\n",
            "           1       0.78      0.64      0.70        11\n",
            "\n",
            "    accuracy                           0.92        78\n",
            "   macro avg       0.86      0.80      0.83        78\n",
            "weighted avg       0.92      0.92      0.92        78\n",
            "\n",
            "0.9230769230769231\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.96        70\n",
            "           1       0.60      0.75      0.67         8\n",
            "\n",
            "    accuracy                           0.92        78\n",
            "   macro avg       0.79      0.85      0.81        78\n",
            "weighted avg       0.93      0.92      0.93        78\n",
            "\n",
            "0.9230769230769231\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95        63\n",
            "           1       0.85      0.73      0.79        15\n",
            "\n",
            "    accuracy                           0.92        78\n",
            "   macro avg       0.89      0.85      0.87        78\n",
            "weighted avg       0.92      0.92      0.92        78\n",
            "\n",
            "0.9230769230769231\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96        69\n",
            "           1       0.75      0.67      0.71         9\n",
            "\n",
            "    accuracy                           0.94        78\n",
            "   macro avg       0.85      0.82      0.83        78\n",
            "weighted avg       0.93      0.94      0.93        78\n",
            "\n",
            "0.9358974358974359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96        67\n",
            "           1       1.00      0.55      0.71        11\n",
            "\n",
            "    accuracy                           0.94        78\n",
            "   macro avg       0.97      0.77      0.83        78\n",
            "weighted avg       0.94      0.94      0.93        78\n",
            "\n",
            "0.9358974358974359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96        68\n",
            "           1       0.78      0.70      0.74        10\n",
            "\n",
            "    accuracy                           0.94        78\n",
            "   macro avg       0.87      0.84      0.85        78\n",
            "weighted avg       0.93      0.94      0.93        78\n",
            "\n",
            "0.9358974358974359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98        65\n",
            "           1       0.92      0.85      0.88        13\n",
            "\n",
            "    accuracy                           0.96        78\n",
            "   macro avg       0.94      0.92      0.93        78\n",
            "weighted avg       0.96      0.96      0.96        78\n",
            "\n",
            "0.9615384615384616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRrqqUK4h4X9"
      },
      "source": [
        "label =[ 'Cholesterol','Glucose','HDL Chol','Chol/HDL ratio','Age','Gender','Height','Weight','BMI','Systolic BP','Diastolic BP','Waist','Hip','Waist/Hip ratio']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQdEmHRwC_dN"
      },
      "source": [
        "FEATURE SELECTION\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWcn6i3b-x2s",
        "outputId": "70d7116b-397d-421b-8d43-a840fde88565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        }
      },
      "source": [
        "def plot_feature_importance(importance,names,model_type):\n",
        "  feature_importance = np.array(importance)\n",
        "  feature_names = np.array(names)\n",
        "\n",
        "#Create a DataFrame using a Dictionary\n",
        "  data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
        "  fi_df = pd.DataFrame(data)\n",
        "\n",
        "#Sort the DataFrame in order decreasing feature importance\n",
        "  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
        "  #Define size of bar plot\n",
        "  plt.figure(figsize=(10,8))\n",
        "#Plot Searborn bar chart\n",
        "  sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
        "#Add chart labels\n",
        "  plt.title(model_type + ' FEATURE IMPORTANCE')\n",
        "  plt.xlabel('FEATURE IMPORTANCE')\n",
        "  plt.ylabel('FEATURE NAMES')\n",
        "plot_feature_importance(RFclassifier.feature_importances_,label,'RANDOM FOREST')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmjppw5MAHVe",
        "outputId": "10d0fe62-3e2e-4ea5-9889-7bc0c4265af6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "sel = VarianceThreshold(threshold=(0.05))\n",
        "\n",
        "x_train_dup=x_train\n",
        "sel.fit_transform(x_train_dup)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.08419461, -0.30039946,  0.0802802 , ..., -0.32211031,\n",
              "        -0.36579722,  0.0142588 ],\n",
              "       [-1.38659323, -0.46783132, -1.28486372, ..., -1.18401784,\n",
              "        -0.88299692, -0.79460407],\n",
              "       [-0.08419461,  3.58774032, -0.39455246, ...,  1.74646775,\n",
              "         2.04780137, -0.12055168],\n",
              "       ...,\n",
              "       [-0.39323835, -0.18877823, -0.15713613, ...,  0.0226527 ,\n",
              "         0.32380237, -0.52498311],\n",
              "       [-1.36451868, -0.39341716, -1.22550963, ..., -1.18401784,\n",
              "        -1.40019662,  0.14906928],\n",
              "       [-1.5852642 , -0.33760654, -0.15713613, ..., -1.18401784,\n",
              "        -0.71059702, -1.1990355 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL0WUAdxCaQ0",
        "outputId": "241254fb-ad38-4a26-e5e4-e2309e042090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "\n",
        "RFclassifier = RandomForestClassifier(n_estimators = 100,random_state=0,warm_start=True)\n",
        "RFclassifier.fit(x_train_dup, y_train)\n",
        "y_pred = RFclassifier.predict(x_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "acc=accuracy_score(y_test, y_pred)\n",
        "print(acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        65\n",
            "           1       0.92      0.92      0.92        13\n",
            "\n",
            "    accuracy                           0.97        78\n",
            "   macro avg       0.95      0.95      0.95        78\n",
            "weighted avg       0.97      0.97      0.97        78\n",
            "\n",
            "0.9743589743589743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e08FFnbC2Ks"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H1ZztRGDEXd"
      },
      "source": [
        "FEATURE SELECTION: METHOD 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-LILWL2DIR8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBpxu8x4KDoG"
      },
      "source": [
        "labelProb =RFclassifier.predict_proba(x_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh36C10_DG4T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92UHmTN7LXzr"
      },
      "source": [
        "alpha=0.75\n",
        "beta=0.4\n",
        "\n",
        "finalProb=[]\n",
        "finalLabelProb=[]\n",
        "#labelProbList=labelProb.tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JDTd_B3LgZu"
      },
      "source": [
        "for i in labelProb:\n",
        " # print(\"list: i is:\",i)\n",
        "  if i[1] > alpha and i[1]> i[0]:\n",
        "    ele =i[1]\n",
        "   # print(\"positive\")\n",
        "    add=1\n",
        "    finalProb.append(add)\n",
        "    finalLabelProb.append(add)\n",
        "\n",
        "  elif i[0]>beta and i[0]>i[1]:\n",
        "   # print(\"negative\")\n",
        "    add=0\n",
        "    finalProb.append(add)\n",
        "    finalLabelProb.append(add)\n",
        "  else:\n",
        "    #print(\"abstention incurred\")\n",
        "    add=2\n",
        "    ##remove prob with target as 2\n",
        "    finalProb.append(add)\n",
        "    \n",
        "  \n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo1y7iePRAMq",
        "outputId": "8dbf3283-22e8-4cc5-e23a-430ec6dcd2ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "index=[]\n",
        "for i, e in enumerate(finalProb):\n",
        "   if e == 2:\n",
        "     \n",
        "     index.append(i)\n",
        "  \n",
        "print(index)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19, 20, 25, 27, 35, 41, 49, 64, 75]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amk-8kp3nb9u"
      },
      "source": [
        "y_test_dup=y_test\n",
        "y_test_dup=y_test_dup.tolist()\n",
        "final_y_test = [i for j, i in enumerate(y_test_dup) if j not in index]\n",
        "\n",
        "\n",
        "#for pos in index:\n",
        "  #print(pos)\n",
        "\n",
        "####use anotehr variable to pop as this is removing and using the same list to remove again and hence th error\n",
        "  #y_test_final=y_test_dup.pop(pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue1WtYGosD8A"
      },
      "source": [
        "# RESULT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJfN5I2lQAmx",
        "outputId": "6d0e802d-6f19-4545-f0a5-b5b0ca69a6d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "#print(confusion_matrix(y_test, y_pred))\n",
        "#print(classification_report(y_test, y_pred))\n",
        "print(accuracy_score(final_y_test, finalLabelProb)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9855072463768116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-fFG9epYyXt"
      },
      "source": [
        "\n",
        "import pickle\n",
        "filename = 'diabetesClassifier.pkl'\n",
        "pickle.dump(RFclassifier, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGwjcO0_RULu"
      },
      "source": [
        "#ROC curves\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, labelProb[:,1])\n",
        "sensitivity = tpr #alpha\n",
        "specificity= 1-fpr #beta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3BvdKrFYq6o",
        "outputId": "d0e01b10-73fe-4818-8fba-ed7e08c49e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "sensitivity"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.07692308, 0.69230769, 0.69230769, 0.92307692,\n",
              "       0.92307692, 0.92307692, 0.92307692, 0.92307692, 0.92307692,\n",
              "       0.92307692, 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lItgiXdCYwp8",
        "outputId": "d00b74d6-c613-4ff1-8a95-c082c676b1f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "specificity"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 1.        , 1.        , 0.98461538, 0.98461538,\n",
              "       0.89230769, 0.83076923, 0.81538462, 0.75384615, 0.69230769,\n",
              "       0.63076923, 0.58461538, 0.53846154, 0.52307692, 0.46153846,\n",
              "       0.38461538, 0.33846154, 0.26153846, 0.16923077, 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaYyUclpU4_i",
        "outputId": "2e3f9f2e-7a17-40a6-8e82-b6831d48ca65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "# plot the roc curve for the model\n",
        "from matplotlib import pyplot\n",
        "\n",
        "pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "pyplot.plot(fpr, tpr, marker='.', label='Random Forest')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jppUL-lMVR90"
      },
      "source": [
        "# calculate the g-mean for each threshold\n",
        "gmeans = np.sqrt(tpr * (1-fpr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVksEBvwVZn7",
        "outputId": "c182b553-8c0d-4833-fbc1-b81d6105efc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ix = np.argmax(gmeans)\n",
        "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.530000, G-Mean=0.953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaQR_xk5VpcU",
        "outputId": "902e3170-1ba5-4f80-95fc-3755e24f711c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "# plot the roc curve for the model\n",
        "pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "pyplot.plot(fpr, tpr, marker='.', label='Random Forest')\n",
        "pyplot.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1kADeqsK4uM",
        "outputId": "ac60582e-1da0-47ee-cc6b-2fa4cae8a9c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# calculate roc curves\n",
        "fpr, tpr, thresholds = roc_curve(y_test, finalProb)\n",
        "# get the best threshold\n",
        "J = tpr - fpr\n",
        "ix = np.argmax(J)\n",
        "best_thresh = thresholds[ix]\n",
        "print('Best Threshold=%f' % (best_thresh))\n",
        "ns_probs = [0 for _ in range(len(final_y_test))]\n",
        "\n",
        "score=roc_auc_score(final_y_test,ns_probs)\n",
        "lr_probs = RFclassifier.predict_proba(x_test)\n",
        "\n",
        "\n",
        "lr_auc = roc_auc_score(y_test, lr_probs)\n",
        "# predict probabilities\n",
        "# keep probabilities for the positive outcome only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "print(lr_probs)\n",
        "score\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=1.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-8fcebcd60ac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mlr_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m# predict probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# keep probabilities for the positive outcome only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                              max_fpr=max_fpr),\n\u001b[1;32m    389\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         return _average_binary_score(partial(_binary_roc_auc_score,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     fpr, tpr, _ = roc_curve(y_true, y_score,\n\u001b[0;32m--> 225\u001b[0;31m                             sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \"\"\"\n\u001b[1;32m    770\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 771\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: bad input shape (78, 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeh1jtc-WNpv",
        "outputId": "10ae9b22-7d69-4df6-ce32-4c08acc806fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# calculate roc curves\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(final_y_test, finalLabelProb)\n",
        "# convert to f score\n",
        "fscore = (2 * precision * recall) / (precision + recall)\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscore)\n",
        "print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n",
        "# plot the roc curve for the model\n",
        "#no_skill = len(final_y_test[final_y_test==1]) / len(final_y_test)\n",
        "#pyplot.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\n",
        "pyplot.plot(recall, precision, marker='.', label='Logistic')\n",
        "# axis labels\n",
        "pyplot.xlabel('Recall')\n",
        "pyplot.ylabel('Precision')\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=1.000000, F-Score=0.889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATfk3xRCnCNV",
        "outputId": "d3a2e34e-2e5f-40b4-b557-8f3c092ae431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pip install streamlit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/fd/a2c8e973ed3a79d46c589f93fdbfcbda2173bd2c631100db4c2883ce1dde/streamlit-0.69.1-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 2.6MB/s \n",
            "\u001b[?25hCollecting enum-compat\n",
            "  Downloading https://files.pythonhosted.org/packages/55/ae/467bc4509246283bb59746e21a1a2f5a8aecbef56b1fa6eaca78cd438c8b/enum_compat-0.0.3-py3-none-any.whl\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/87/31810f044f2dd2101f2ecd85c5539bbddef4cff47df39eb0be895cc23af4/boto3-1.15.16-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (4.1.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (from streamlit) (0.14.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from streamlit) (2.23.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.6/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from streamlit) (20.4)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (1.1.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from streamlit) (0.10.1)\n",
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/d7/b2b0672e0331567157adf9281f41ee731c412ee518ca5e6552c27fa73c91/GitPython-3.1.9-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 42.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from streamlit) (0.8.1)\n",
            "Collecting botocore>=1.13.44\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/9e/afa41db0cd911869305bb783b9b021be67ea23c8b7b317caa46632dbf3cf/botocore-1.18.16-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (5.1.1)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/1e/296f4108bf357e684617a776ecaf06ee93b43e30c35996dfac1aa985aa6c/pydeck-0.5.0b1-py2.py3-none-any.whl (4.4MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4MB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (3.12.4)\n",
            "Collecting watchdog\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from streamlit) (2.8.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from streamlit) (1.18.5)\n",
            "Collecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/41/4a/3360ff3cf2b4a1b9721ac1fbff5f84663f41047d9874b3aa1ac82e862c44/validators-0.18.1-py3-none-any.whl\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.6/dist-packages (from streamlit) (4.1.1)\n",
            "Collecting blinker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 46.1MB/s \n",
            "\u001b[?25hCollecting base58\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/03/58572025c77b9e6027155b272a1b96298e711cd4f95c24967f7137ab0c4b/base58-2.0.1-py3-none-any.whl\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit) (2.11.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow->streamlit) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->streamlit) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->streamlit) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from tzlocal->streamlit) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->streamlit) (2.4.7)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[?25hCollecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/19/c2812690d8b340987eecd2cbc18549b1d130b94c5d97fcbe49f5f8710edf/ipykernel-5.3.4-py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.5.1)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->streamlit) (50.3.0)\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from validators->streamlit) (4.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.0.7)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (19.0.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.6.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.2.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Building wheels for collected packages: watchdog, blinker, pathtools\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73873 sha256=b1bc8dc791b8c9a1379404142c6f3d1717b162572d15e7a477c11a1c73849fa6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp36-none-any.whl size=13450 sha256=e016297929ddcc3b915e16a27fdb2652a17dc00bf098aa923dc216ec08bfae8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=300102bb6b4bae8e598fe857796cefbc1f49ce0e736c97b524a6da4068a3a847\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built watchdog blinker pathtools\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.3.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: enum-compat, jmespath, botocore, s3transfer, boto3, smmap, gitdb, gitpython, ipykernel, pydeck, pathtools, watchdog, validators, blinker, base58, streamlit\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed base58-2.0.1 blinker-1.4 boto3-1.15.16 botocore-1.18.16 enum-compat-0.0.3 gitdb-4.0.5 gitpython-3.1.9 ipykernel-5.3.4 jmespath-0.10.0 pathtools-0.1.2 pydeck-0.5.0b1 s3transfer-0.3.3 smmap-3.0.4 streamlit-0.69.1 validators-0.18.1 watchdog-0.10.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaOkgwitLwHY",
        "outputId": "ae2dbbc2-ee71-44fc-85d0-15912caf452f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import streamlit as st \n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ContextualVersionConflict",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mContextualVersionConflict\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-2e4ce17115ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/streamlit/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# This used to be pkg_resources.require('streamlit') but it would cause\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# pex files to fail. See #394 for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pkg_resources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"streamlit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontextlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_contextlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_distribution\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_provider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected string, Requirement, or Distribution\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_provider\u001b[0;34m(moduleOrReq)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;34m\"\"\"Return an IResourceProvider for the named module or requirement\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mworking_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mrequire\u001b[0;34m(self, *requirements)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mincluded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meven\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mwere\u001b[0m \u001b[0malready\u001b[0m \u001b[0mactivated\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mworking\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m         \"\"\"\n\u001b[0;32m--> 884\u001b[0;31m         \u001b[0mneeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequirements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneeded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0;31m# Oops, the \"best\" so far conflicts with a dependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0mdependent_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequired_by\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mVersionConflict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdependent_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# push the new requirements onto the stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mContextualVersionConflict\u001b[0m: (ipykernel 4.10.1 (/usr/local/lib/python3.6/dist-packages), Requirement.parse('ipykernel>=5.1.2; python_version >= \"3.4\"'), {'pydeck'})"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrA72u1Bnbl4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-I8bvTDL-5M",
        "outputId": "62e87ae7-dc3e-454c-83fd-4693068ba151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "pickle_in = open(\"bestClassifier.pkl\",\"rb\")\n",
        "classifier=pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-4742d6a86ba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bestClassifier.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bestClassifier.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b28TYI6_MMbE"
      },
      "source": [
        "def welcome():\n",
        "    return \"Welcome All\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL75heSqMQcJ"
      },
      "source": [
        "def predict_note_authentication(SESSO, AGE, WBC, Piastrine, Neutrofili, Monociti, Eosinofili, Basofili, AST, ALT, ALP, GGT, LDH):\n",
        "    \n",
        "    \"\"\"Let's Authenticate the Banks Note \n",
        "    This is using docstrings for specifications.\n",
        "    ---\n",
        "    parameters:  \n",
        "      - name: SESSO\n",
        "        in: query\n",
        "        type: number\n",
        "        required: true\n",
        "      - name: AGE\n",
        "        in: query\n",
        "        type: number\n",
        "        required: true\n",
        "      - name: WBC\n",
        "        in: query\n",
        "        type: number\n",
        "        required: true\n",
        "      - name: Piastrine\n",
        "        in: query\n",
        "        type: number\n",
        "        required: true\n",
        "      - name: Neutrofili\n",
        "        in: query\n",
        "        type: number\n",
        "        required: true\n",
        "      - name: Monociti\n",
        "        in: query\n",
        "        type: number\n",
        "        required: true\n",
        "      - name: Eosinofili\n",
        "        in: query\n",
        "        type: number\n",
        "        required: true\n",
        "      - name: Basofili\n",
        "        in: query\n",
        "        type: number\n",
        "        required: true\n",
        "      - name: AST\n",
        "        in: query\n",
        "        type: number\n",
        "        required: true\n",
        "      - name: ALT\n",
        "        in: query\n",
        "        type: number\n",
        "        required: true\n",
        "      - name: ALP\n",
        "        in: query\n",
        "        type: number\n",
        "        required: true\n",
        "      - name: GGT\n",
        "        in: query\n",
        "        type: number\n",
        "        required: true\n",
        "      - name: LDH\n",
        "        in: query\n",
        "        type: number\n",
        "        required: true\n",
        "    responses:\n",
        "        200:\n",
        "            description: The output values\n",
        "        \n",
        "    \"\"\"\n",
        "   \n",
        "    prediction=classifier.predict([[SESSO, AGE, WBC, Piastrine, Neutrofili, Monociti, Eosinofili, Basofili, AST, ALT, ALP, GGT, LDH]])\n",
        "    print(prediction)\n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5GiZycPMWE8"
      },
      "source": [
        "def main():\n",
        "    st.title(\"Covid'19\")\n",
        "    html_temp = \"\"\"\n",
        "    <div style=\"background-color:tomato;padding:10px\">\n",
        "    <h2 style=\"color:white;text-align:center;\">Covid'19 </h2>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    st.markdown(html_temp,unsafe_allow_html=True)\n",
        "    SESSO = st.text_input(\"Gender (For Male type: 0 / For Female type: 1)\",\"Type Here\")\n",
        "    AGE = st.text_input(\"AGE\",\"Type Here\")\n",
        "    WBC = st.text_input(\"WBC\",\"Type Here\")\n",
        "    Piastrine = st.text_input(\"Piastrine\",\"Type Here\")\n",
        "    Neutrofili = st.text_input(\"Neutrofili\",\"Type Here\")\n",
        "    Monociti = st.text_input(\"Monociti\",\"Type Here\")\n",
        "    Eosinofili = st.text_input(\"Eosinofili\",\"Type Here\")\n",
        "    Basofili = st.text_input(\"Basofili\",\"Type Here\")\n",
        "    AST = st.text_input(\"AST\",\"Type Here\")\n",
        "    ALT = st.text_input(\"ALT\",\"Type Here\")\n",
        "    ALP = st.text_input(\"ALP\",\"Type Here\")\n",
        "    GGT = st.text_input(\"GGT\",\"Type Here\")\n",
        "    LDH = st.text_input(\"LDH\",\"Type Here\")\n",
        "\n",
        "    result=\"\"\n",
        "    if st.button(\"Predict\"):\n",
        "        result=predict_note_authentication(SESSO, AGE, WBC, Piastrine, Neutrofili, Monociti, Eosinofili, Basofili, AST, ALT, ALP, GGT, LDH)\n",
        "    st.success('The output is  {}'.format(result))\n",
        "    if st.button(\"About\"):\n",
        "        st.text(\"Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus.\")\n",
        "        st.text(\"Most people who fall sick with COVID-19 will experience mild to moderate symptoms and recover without special treatment.\")\n",
        "\n",
        "if __name__=='__main__':\n",
        "    main()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meOvNWJbMbQ4"
      },
      "source": [
        "import keras\n",
        "# from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LeakyReLU,PReLU,ELU\n",
        "from keras.layers import Dropout\n",
        "from keras import backend as K\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import History\n",
        "# from keras.callbacks import "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kxoKtjooDgF"
      },
      "source": [
        "# Train Test Split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BeAkjdDjKW1"
      },
      "source": [
        "classifier = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUztHqjnnjYP",
        "outputId": "ec669141-1711-47dd-c6fa-98b71c0c5653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "classifier.add(Dense(units = 7,kernel_initializer='uniform', activation = 'relu',input_dim = 14))\n",
        "classifier.add(Dense(units = 7,kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dense(units = 3,kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dense(units = 3,kernel_initializer = 'uniform', activation = 'relu'))\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "# Compiling the ANN\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "classifier.compile(optimizer=opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "# Fitting the ANN to the Training set\n",
        "model_history=classifier.fit(x_train, y_train,validation_split=0.20, batch_size = 5, epochs = 1000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 2/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 3/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 4/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 5/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 6/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 7/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 8/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 9/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 10/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 11/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 12/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 13/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 14/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 15/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 16/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 17/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 18/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 19/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 20/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 21/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 22/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 23/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 24/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 25/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 26/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 27/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 28/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 29/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 30/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 31/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 32/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 33/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 34/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 35/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 36/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 37/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 38/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 39/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 40/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 41/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 42/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 43/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 44/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 45/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 46/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 47/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 48/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 49/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 50/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 51/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 52/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 53/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 54/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 55/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 56/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 57/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 58/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 59/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 60/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 61/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 62/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 63/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 64/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 65/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 66/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 67/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 68/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 69/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 70/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 71/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 72/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 73/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 74/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 75/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 76/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 77/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 78/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 79/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 80/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 81/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 82/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 83/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 84/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 85/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 86/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 87/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 88/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 89/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 90/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 91/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 92/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 93/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 94/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 95/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 96/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 97/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 98/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 99/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 100/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 101/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 102/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 103/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 104/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 105/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 106/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 107/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 108/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 109/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 110/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 111/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 112/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 113/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 114/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 115/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 116/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 117/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 118/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 119/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 120/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 121/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 122/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 123/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 124/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 125/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 126/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 127/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 128/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 129/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 130/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 131/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 132/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 133/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 134/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 135/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 136/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 137/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 138/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 139/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 140/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 141/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 142/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 143/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 144/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 145/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 146/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 147/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 148/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 149/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 150/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 151/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 152/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 153/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 154/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 155/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 156/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 157/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 158/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 159/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 160/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 161/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 162/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 163/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 164/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 165/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 166/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 167/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 168/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 169/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 170/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 171/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 172/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 173/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 174/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 175/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 176/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 177/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 178/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 179/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 180/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 181/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 182/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 183/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 184/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 185/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 186/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 187/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 188/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 189/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 190/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 191/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 192/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 193/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 194/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 195/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 196/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 197/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 198/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 199/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 200/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 201/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 202/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 203/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 204/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 205/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 206/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 207/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 208/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 209/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 210/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 211/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 212/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 213/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 214/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 215/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 216/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 217/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 218/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 219/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 220/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 221/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 222/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 223/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 224/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 225/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 226/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 227/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 228/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 229/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 230/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 231/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 232/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 233/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 234/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 235/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 236/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 237/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 238/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 239/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 240/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 241/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 242/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 243/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 244/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 245/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 246/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 247/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 248/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 249/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 250/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 251/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 252/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 253/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 254/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 255/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 256/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 257/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 258/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 259/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 260/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 261/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 262/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 263/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 264/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 265/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 266/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 267/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 268/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 269/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 270/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 271/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 272/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 273/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 274/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 275/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 276/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 277/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 278/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 279/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 280/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 281/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 282/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 283/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 284/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 285/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 286/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 287/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 288/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 289/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 290/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 291/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 292/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 293/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 294/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 295/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 296/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 297/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 298/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 299/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 300/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 301/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 302/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 303/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 304/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 305/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 306/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 307/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 308/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 309/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 310/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 311/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 312/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 313/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 314/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 315/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 316/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 317/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 318/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 319/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 320/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 321/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 322/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 323/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 324/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 325/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 326/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 327/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 328/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 329/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 330/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 331/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 332/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 333/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 334/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 335/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 336/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 337/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 338/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 339/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 340/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 341/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 342/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 343/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 344/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 345/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 346/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 347/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 348/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 349/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 350/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 351/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 352/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 353/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 354/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 355/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 356/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 357/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 358/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 359/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 360/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 361/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 362/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 363/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 364/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 365/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 366/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 367/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 368/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 369/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 370/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 371/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 372/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 373/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 374/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 375/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 376/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 377/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 378/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 379/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 380/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 381/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 382/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 383/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 384/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 385/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 386/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 387/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 388/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 389/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 390/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 391/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 392/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 393/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 394/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 395/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 396/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 397/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 398/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 399/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 400/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 401/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 402/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 403/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 404/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 405/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 406/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 407/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 408/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 409/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 410/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 411/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 412/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 413/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 414/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 415/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 416/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 417/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 418/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 419/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 420/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 421/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 422/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 423/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 424/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 425/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 426/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 427/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 428/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 429/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 430/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 431/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 432/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 433/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 434/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 435/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 436/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 437/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 438/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 439/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 440/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 441/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 442/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 443/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 444/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 445/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 446/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 447/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 448/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 449/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 450/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 451/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 452/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 453/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 454/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 455/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 456/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 457/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 458/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 459/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 460/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 461/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 462/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 463/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 464/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 465/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 466/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 467/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 468/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 469/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 470/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 471/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 472/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 473/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 474/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 475/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 476/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 477/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 478/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 479/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 480/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 481/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 482/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 483/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 484/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 485/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 486/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 487/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 488/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 489/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 490/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 491/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 492/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 493/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 494/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 495/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 496/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 497/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 498/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 499/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 500/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 501/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 502/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 503/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 504/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 505/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 506/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 507/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 508/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 509/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 510/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 511/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 512/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 513/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 514/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 515/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 516/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 517/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 518/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 519/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 520/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 521/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 522/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 523/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 524/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 525/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 526/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 527/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 528/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 529/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 530/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 531/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 532/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 533/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 534/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 535/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 536/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 537/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 538/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 539/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 540/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 541/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 542/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 543/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 544/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 545/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 546/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 547/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 548/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 549/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 550/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 551/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 552/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 553/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 554/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 555/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 556/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 557/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 558/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 559/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 560/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 561/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 562/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 563/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 564/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 565/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 566/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 567/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 568/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 569/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 570/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 571/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 572/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 573/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 574/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 575/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 576/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 577/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 578/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 579/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 580/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 581/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 582/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 583/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 584/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 585/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 586/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 587/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 588/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 589/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 590/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 591/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 592/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 593/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 594/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 595/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 596/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 597/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 598/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 599/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 600/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 601/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 602/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 603/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 604/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 605/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 606/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 607/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 608/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 609/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 610/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 611/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 612/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 613/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 614/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 615/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 616/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 617/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 618/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 619/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 620/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 621/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 622/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 623/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 624/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 625/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 626/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 627/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 628/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 629/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 630/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 631/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 632/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 633/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 634/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 635/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 636/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 637/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 638/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 639/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 640/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 641/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 642/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 643/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 644/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 645/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 646/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 647/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 648/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 649/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 650/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 651/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 652/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 653/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 654/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 655/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 656/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 657/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 658/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 659/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 660/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 661/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 662/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 663/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 664/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 665/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 666/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 667/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 668/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 669/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 670/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 671/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 672/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 673/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 674/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 675/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 676/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 677/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 678/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 679/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 680/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 681/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 682/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 683/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 684/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 685/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 686/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 687/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 688/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 689/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 690/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 691/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 692/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 693/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 694/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 695/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 696/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 697/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 698/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 699/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 700/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 701/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 702/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 703/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 704/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 705/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 706/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 707/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 708/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 709/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 710/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 711/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 712/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 713/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 714/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 715/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 716/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 717/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 718/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 719/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 720/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 721/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 722/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 723/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 724/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 725/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 726/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 727/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 728/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 729/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 730/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 731/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 732/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 733/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 734/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 735/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 736/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 737/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 738/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 739/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 740/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 741/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 742/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 743/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 744/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 745/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 746/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 747/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 748/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 749/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 750/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 751/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 752/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 753/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 754/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 755/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 756/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 757/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 758/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 759/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 760/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 761/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 762/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 763/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 764/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 765/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 766/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 767/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 768/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 769/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 770/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 771/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 772/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 773/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 774/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 775/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 776/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 777/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 778/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 779/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 780/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 781/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 782/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 783/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 784/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 785/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 786/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 787/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 788/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 789/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 790/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 791/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 792/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 793/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 794/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 795/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 796/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 797/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 798/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 799/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 800/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 801/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 802/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 803/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 804/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 805/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 806/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 807/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 808/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 809/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 810/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 811/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 812/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 813/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 814/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 815/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 816/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 817/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 818/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 819/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 820/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 821/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 822/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 823/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 824/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 825/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 826/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 827/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 828/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 829/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 830/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 831/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 832/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 833/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 834/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 835/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 836/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 837/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 838/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 839/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 840/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 841/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 842/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 843/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 844/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 845/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 846/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 847/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 848/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 849/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 850/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 851/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 852/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 853/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 854/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 855/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 856/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 857/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 858/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 859/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 860/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 861/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 862/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 863/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 864/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 865/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 866/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 867/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 868/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 869/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 870/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 871/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 872/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 873/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 874/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 875/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 876/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 877/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 878/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 879/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 880/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 881/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 882/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 883/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 884/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 885/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 886/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 887/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 888/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 889/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 890/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 891/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 892/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 893/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 894/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 895/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 896/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 897/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 898/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 899/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 900/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 901/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 902/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 903/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 904/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 905/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 906/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 907/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 908/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 909/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 910/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 911/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 912/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 913/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 914/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 915/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 916/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 917/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 918/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 919/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 920/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 921/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 922/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 923/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 924/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 925/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 926/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 927/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 928/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 929/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 930/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 931/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 932/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 933/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 934/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 935/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 936/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 937/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 938/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 939/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 940/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 941/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 942/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 943/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 944/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 945/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 946/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 947/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 948/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 949/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 950/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 951/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 952/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 953/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 954/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 955/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 956/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 957/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 958/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 959/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 960/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 961/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 962/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 963/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 964/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 965/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 966/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 967/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 968/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 969/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 970/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 971/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 972/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 973/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 974/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 975/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 976/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 977/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 978/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 979/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 980/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 981/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 982/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 983/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 984/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 985/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 986/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 987/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 988/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 989/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 990/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 991/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 992/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 993/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 994/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 995/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 996/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 997/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 998/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 999/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n",
            "Epoch 1000/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6554 - val_loss: 0.0000e+00 - val_accuracy: 0.5778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKErXqqgnn4l",
        "outputId": "d3b8a51e-c8aa-4667-fc94-acf241a38f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "    from keras import regularizers\n",
        "    from keras.layers import Dense, Dropout, BatchNormalization\n",
        "    from keras import optimizers\n",
        "\n",
        "\n",
        "    Ndims=1\n",
        "    NClasses = 2\n",
        "    Drop = 0.5\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, kernel_regularizer= regularizers.l2(0.001), input_dim=Ndims, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(256, kernel_regularizer= regularizers.l2(0.001), kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dropout(DropRate))\n",
        "    model.add(Dense(128, kernel_regularizer= regularizers.l2(0.001), kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(128, kernel_regularizer= regularizers.l2(0.001), kernel_initializer='normal', activation='relu'))\n",
        "    model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "    model.add(Dense(64, kernel_regularizer= regularizers.l2(0.001), kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(32, kernel_regularizer= regularizers.l2(0.001), kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dropout(DropRate))\n",
        "    model.add(Dense(32, kernel_regularizer= regularizers.l2(0.001), kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dropout(DropRate))\n",
        "    model.add(Dense(NClasses, kernel_initializer='normal', activation='softmax'))\n",
        "    \n",
        "    #Tune an optimiser\n",
        "    Optim = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Optim, metrics = ['accuracy'])\n",
        "    model_history=classifier.fit(x_train, y_train, batch_size = 5, epochs = 30)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 2/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 3/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 4/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 5/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 6/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 7/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 8/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 9/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 10/30\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 11/30\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 12/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 13/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 14/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 15/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 16/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 17/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 18/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 19/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 20/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 21/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 22/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 23/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 24/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 25/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 26/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 27/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 28/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 29/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n",
            "Epoch 30/30\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI4ckX_ywTi6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}